{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b79e98-f0e7-439c-8ab9-78665f77cd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/locolinux2/miniconda3/envs/m_quant/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [12:28<00:00,  1.46s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [01:08<00:00,  1.46s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:30<00:00,  1.39s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:51<00:00,  1.52s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:15<00:00,  1.25s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.51s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.42s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.45s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:19<00:00,  1.42s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:14<00:00,  1.34s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:46<00:00,  1.34s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.41s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.55s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:01<00:00,  2.06s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:13<00:00,  1.55s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466/466 [14:44<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train per-centre sizes: {1: 511, 2: 6, 3: 15, 4: 47, 5: 22, 6: 34, 7: 12, 8: 8, 9: 4, 10: 8, 11: 14, 12: 11, 13: 35, 14: 6, 15: 13, 16: 30, 17: 9}\n",
      "validation size: 466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, copy, time, random, torch, numpy as np                                 # ← your own\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "import glob, nibabel as nib, pandas as pd\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Orientationd, ScaleIntensityd,\n",
    "    RandFlipd, RandSpatialCropd, Compose, SelectItemsd\n",
    ")\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------------------------------\n",
    "# 0. paths & meta-data (unchanged) ---------------------------\n",
    "# -----------------------------------------------------------\n",
    "BRATS_DIR = \"/mnt/d/Datasets/FETS_data/MICCAI_FeTS2022_TrainingData\"\n",
    "CSV_PATH  = f\"{BRATS_DIR}/partitioning_1.csv\"\n",
    "MODALITIES = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY  = \"seg\"\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. read partition file  ➜  { id : [subjects] } ------------\n",
    "# -----------------------------------------------------------\n",
    "part_df       = pd.read_csv(CSV_PATH)\n",
    "partition_map = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list).to_dict()\n",
    ")                               # keys are 1 … 23\n",
    "\n",
    "VAL_CENTRES = {18, 19, 20, 21, 22, 23}          # ← our hold-out set\n",
    "# VAL_CENTRES = {22, 23}          # ← our sanity set\n",
    "\n",
    "# split once, reuse everywhere\n",
    "train_partitions = {cid: sids for cid, sids in partition_map.items()\n",
    "                    if cid not in VAL_CENTRES}\n",
    "val_subjects     = sum((partition_map[cid] for cid in VAL_CENTRES), [])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. helper to build MONAI-style record dicts ----------------\n",
    "# -----------------------------------------------------------\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        sdir = f\"{BRATS_DIR}/{sid}\"\n",
    "        rec  = {m: f\"{sdir}/{sid}_{m}.nii.gz\" for m in MODALITIES}\n",
    "        rec[\"seg\"] = f\"{sdir}/{sid}_{LABEL_KEY}.nii.gz\"\n",
    "        recs.append(rec)\n",
    "    return recs\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. transforms (unchanged) ---------------------------------\n",
    "# -----------------------------------------------------------\n",
    "IMG_KEYS = MODALITIES + [LABEL_KEY]\n",
    "train_tf = Compose([\n",
    "    LoadImaged(keys=IMG_KEYS), EnsureChannelFirstd(keys=IMG_KEYS),\n",
    "    Orientationd(keys=IMG_KEYS, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=IMG_KEYS, minv=-1.0, maxv=1.0),\n",
    "    SelectItemsd(keys=IMG_KEYS),\n",
    "])\n",
    "val_tf = Compose([\n",
    "    LoadImaged(keys=IMG_KEYS), EnsureChannelFirstd(keys=IMG_KEYS),\n",
    "    Orientationd(keys=IMG_KEYS, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=MODALITIES, minv=-1.0, maxv=1.0),   # masks untouched\n",
    "    SelectItemsd(keys=IMG_KEYS),\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. MONAI CacheDatasets ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "# ── client-wise training sets ───────────────────────────────\n",
    "CUT_OFF, FRAC, SEED = 18, 1, 42\n",
    "rng = random.Random(SEED)\n",
    "\n",
    "train_datasets = {}\n",
    "for cid, subj_ids in train_partitions.items():\n",
    "    if cid > CUT_OFF:                                    # keep your cap\n",
    "        break\n",
    "    k = max(1, int(len(subj_ids) * FRAC))                # e.g. 30 %\n",
    "    sample_ids = rng.sample(subj_ids, k)\n",
    "    train_datasets[cid] = CacheDataset(\n",
    "        build_records(sample_ids), transform=train_tf, cache_rate=1\n",
    "    )\n",
    "\n",
    "# ── single validation dataset made from *all* val subjects ─\n",
    "test_dataset = CacheDataset(\n",
    "    build_records(val_subjects), transform=val_tf, cache_rate=1\n",
    ")\n",
    "\n",
    "print(\"train per-centre sizes:\", {k: len(v) for k, v in train_datasets.items()})\n",
    "print(\"validation size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc046f34-4c0a-474c-8016-99d86045c431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation size: 466\n"
     ]
    }
   ],
   "source": [
    "print(\"validation size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "381f8fa9-30a1-4942-b36b-0c60a58b22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([1, 3, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "from seg_models import *      # adjust path / PYTHONPATH\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = ResUNet3D(4,3).to(device)\n",
    "\n",
    "# quick dummy forward\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 4, 96, 96, 96, device=device)\n",
    "    logits = model(dummy)\n",
    "print(\"logits shape:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf826f6-cd7b-44b6-9c2a-4b81e6e04356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice before any training: 0.011921419762074947\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# 2. helper: Dice on whole/TC/ET averaged to a scalar --------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def dice3(model, test_dataset):\n",
    "    model.eval()\n",
    "    if len(test_dataset) == 0:\n",
    "        raise RuntimeError(f\"No validation cases found – check {VAL_DIR} and glob pattern.\")\n",
    "    loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    dsum = torch.zeros(3, device=device)\n",
    "    for batch in loader:\n",
    "        img = torch.cat([batch[k] for k in (\"flair\",\"t1\",\"t1ce\",\"t2\")],1).to(device)\n",
    "        raw = batch[\"seg\"].squeeze(1).cpu().numpy()\n",
    "        target = torch.tensor(preprocess_mask_labels(raw),\n",
    "                              dtype=torch.float32, device=device)\n",
    "        logits = model(img)\n",
    "        pred = torch.nn.functional.one_hot(\n",
    "                   torch.argmax(logits,1), num_classes=3\n",
    "               ).permute(0,4,1,2,3).float()\n",
    "        inter = 2*(pred*target).sum((2,3,4))\n",
    "        denom = (pred+target).sum((2,3,4))+1e-6\n",
    "        dsum += (inter/denom).squeeze(0)\n",
    "\n",
    "\n",
    "    return (dsum/len(loader)).mean().item()\n",
    "\n",
    "global_model = ResUNet3D(4,3).to(device)\n",
    "print(\"Dice before any training:\", dice3(global_model, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eb953-eef2-4c1f-a07b-6345d342c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange   # trange == tqdm(range())\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# 1. one-client update (returns weights + mean loss)          │\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def local_train(model, loader, lr=1e-4, epochs=1):\n",
    "    crit = BCEDiceLoss().to(device)\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for _ in range(epochs):\n",
    "        running = 0.0\n",
    "        for img_dict in loader:\n",
    "            img = torch.cat([img_dict[k] for k in (\"flair\", \"t1\", \"t1ce\", \"t2\")], 1).to(device)\n",
    "            msk = preprocess_mask_labels(img_dict[\"seg\"].squeeze(1).numpy())\n",
    "            msk = torch.tensor(msk, dtype=torch.float32, device=device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(img), msk)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "        losses.append(running / len(loader))          # epoch-mean\n",
    "\n",
    "    return model.state_dict(), np.mean(losses)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# 2. FedAvg training loop (simple tqdm + clean prints)        │\n",
    "# ────────────────────────────────────────────────────────────\n",
    "EPOCHS, LOCAL_EPOCHS, LR, BATCH = 50, 1, 1e-4, 1          # dial as needed\n",
    "idxs_users = list(train_datasets.keys())\n",
    "sizes      = {k: len(ds) for k, ds in train_datasets.items()}\n",
    "fractions  = [sizes[k] / sum(sizes.values()) for k in idxs_users]\n",
    "\n",
    "global_model = ResUNet3D(4, 3).to(device)\n",
    "print(f\"Dice before training: {dice3(global_model, test_dataset):.4f}\")\n",
    "\n",
    "for rnd in trange(1, EPOCHS + 1, desc=\"Global rounds\"):\n",
    "    local_weights, client_losses = [], []\n",
    "\n",
    "    for cid in tqdm(idxs_users, desc=\" clients\", leave=False):\n",
    "        loader = DataLoader(train_datasets[cid], batch_size=BATCH, shuffle=True)\n",
    "        # deep-copy so each user starts from the same global weights\n",
    "        w, loss = local_train(copy.deepcopy(global_model), loader,\n",
    "                              lr=LR, epochs=LOCAL_EPOCHS)\n",
    "        local_weights.append(w)\n",
    "        client_losses.append(loss)\n",
    "\n",
    "    # FedAvg\n",
    "    global_model.load_state_dict(average_weights(local_weights, fractions))\n",
    "\n",
    "    mean_loss = np.mean(client_losses)\n",
    "    mean_dice = dice3(global_model, test_dataset)\n",
    "    print(f\"Round {rnd:02d}:  mean-loss = {mean_loss:.4f}   mean-Dice = {mean_dice:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
