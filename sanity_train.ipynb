{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b79e98-f0e7-439c-8ab9-78665f77cd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                              | 80/153 [01:11<00:56,  1.30it/s]"
     ]
    }
   ],
   "source": [
    "import os, copy, time, random, torch, numpy as np                                 # ← your own\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "import glob, nibabel as nib, pandas as pd\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Orientationd, ScaleIntensityd,\n",
    "    RandFlipd, RandSpatialCropd, Compose, SelectItemsd\n",
    ")\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------------------------------\n",
    "# 0. paths & meta-data (unchanged) ---------------------------\n",
    "# -----------------------------------------------------------\n",
    "BRATS_DIR = \"/mnt/c/Datasets/MICCAI_FeTS2022_TrainingData\"\n",
    "CSV_PATH  = f\"{BRATS_DIR}/partitioning_1.csv\"\n",
    "MODALITIES = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY  = \"seg\"\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. read partition file  ➜  { id : [subjects] } ------------\n",
    "# -----------------------------------------------------------\n",
    "part_df       = pd.read_csv(CSV_PATH)\n",
    "partition_map = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list).to_dict()\n",
    ")                               # keys are 1 … 23\n",
    "\n",
    "VAL_CENTRES = {18, 19, 20, 21, 22, 23}          # ← our hold-out set\n",
    "\n",
    "# split once, reuse everywhere\n",
    "train_partitions = {cid: sids for cid, sids in partition_map.items()\n",
    "                    if cid not in VAL_CENTRES}\n",
    "val_subjects     = sum((partition_map[cid] for cid in VAL_CENTRES), [])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. helper to build MONAI-style record dicts ----------------\n",
    "# -----------------------------------------------------------\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        sdir = f\"{BRATS_DIR}/{sid}\"\n",
    "        rec  = {m: f\"{sdir}/{sid}_{m}.nii.gz\" for m in MODALITIES}\n",
    "        rec[\"seg\"] = f\"{sdir}/{sid}_{LABEL_KEY}.nii.gz\"\n",
    "        recs.append(rec)\n",
    "    return recs\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. transforms (unchanged) ---------------------------------\n",
    "# -----------------------------------------------------------\n",
    "IMG_KEYS = MODALITIES + [LABEL_KEY]\n",
    "train_tf = Compose([\n",
    "    LoadImaged(keys=IMG_KEYS), EnsureChannelFirstd(keys=IMG_KEYS),\n",
    "    Orientationd(keys=IMG_KEYS, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=IMG_KEYS, minv=-1.0, maxv=1.0),\n",
    "    SelectItemsd(keys=IMG_KEYS),\n",
    "])\n",
    "val_tf = Compose([\n",
    "    LoadImaged(keys=IMG_KEYS), EnsureChannelFirstd(keys=IMG_KEYS),\n",
    "    Orientationd(keys=IMG_KEYS, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=MODALITIES, minv=-1.0, maxv=1.0),   # masks untouched\n",
    "    SelectItemsd(keys=IMG_KEYS),\n",
    "])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. MONAI CacheDatasets ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "# ── client-wise training sets ───────────────────────────────\n",
    "CUT_OFF, FRAC, SEED = 4, 0.3, 42\n",
    "rng = random.Random(SEED)\n",
    "\n",
    "train_datasets = {}\n",
    "for cid, subj_ids in train_partitions.items():\n",
    "    if cid > CUT_OFF:                                    # keep your cap\n",
    "        break\n",
    "    k = max(1, int(len(subj_ids) * FRAC))                # e.g. 30 %\n",
    "    sample_ids = rng.sample(subj_ids, k)\n",
    "    train_datasets[cid] = CacheDataset(\n",
    "        build_records(sample_ids), transform=train_tf, cache_rate=1\n",
    "    )\n",
    "\n",
    "# ── single validation dataset made from *all* val subjects ─\n",
    "test_dataset = CacheDataset(\n",
    "    build_records(val_subjects), transform=val_tf, cache_rate=1\n",
    ")\n",
    "\n",
    "print(\"train per-centre sizes:\", {k: len(v) for k, v in train_datasets.items()})\n",
    "print(\"validation size:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf826f6-cd7b-44b6-9c2a-4b81e6e04356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# 2. helper: Dice on whole/TC/ET averaged to a scalar --------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def dice3(model, test_dataset):\n",
    "    model.eval()\n",
    "    if len(test_dataset) == 0:\n",
    "        raise RuntimeError(f\"No validation cases found – check {VAL_DIR} and glob pattern.\")\n",
    "    loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    dsum = torch.zeros(3, device=device)\n",
    "    for batch in loader:\n",
    "        img = torch.cat([batch[k] for k in (\"flair\",\"t1\",\"t1ce\",\"t2\")],1).to(device)\n",
    "        raw = batch[\"seg\"].squeeze(1).cpu().numpy()\n",
    "        target = torch.tensor(preprocess_mask_labels(raw),\n",
    "                              dtype=torch.float32, device=device)\n",
    "        logits = model(img)\n",
    "        pred = torch.nn.functional.one_hot(\n",
    "                   torch.argmax(logits,1), num_classes=3\n",
    "               ).permute(0,4,1,2,3).float()\n",
    "        inter = 2*(pred*target).sum((2,3,4))\n",
    "        denom = (pred+target).sum((2,3,4))+1e-6\n",
    "        dsum += (inter/denom).squeeze(0)\n",
    "\n",
    "\n",
    "    return (dsum/len(loader)).mean().item()\n",
    "\n",
    "global_model = ResUNet3D(4,3).to(device)\n",
    "print(\"Dice before any training:\", dice3(global_model, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eb953-eef2-4c1f-a07b-6345d342c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 3. local update (single epoch, no AMP, no fancy stuff) -----------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "def local_train(model, loader, lr=1e-4, ep=1):\n",
    "    crit = BCEDiceLoss().to(device)\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for _ in range(ep):\n",
    "        for batch in loader:\n",
    "            img = torch.cat([batch[k] for k in (\"flair\",\"t1\",\"t1ce\",\"t2\")],1).to(device)\n",
    "            msk = preprocess_mask_labels(batch[\"seg\"].squeeze(1).numpy())\n",
    "            msk = torch.tensor(msk, dtype=torch.float32, device=device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(img), msk)\n",
    "            loss.backward(); opt.step()\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 4. FedAvg training loop ------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "EPOCHS, LOCAL_EP, LR, BATCH = 2, 1, 1e-4, 2        # keep tiny for sanity run\n",
    "idxs_users = list(train_datasets.keys())\n",
    "sizes = {k:len(v) for k,v in train_datasets.items()}\n",
    "frac  = [sizes[k]/sum(sizes.values()) for k in idxs_users]\n",
    "\n",
    "\n",
    "for rnd in tqdm(range(1, EPOCHS+1)):\n",
    "    local_w, losses = [], []\n",
    "    for cid in idxs_users:\n",
    "        loader = DataLoader(train_datasets[cid], batch_size=BATCH, shuffle=True)\n",
    "        mdl = copy.deepcopy(global_model)\n",
    "        local_train(mdl, loader, lr=LR, ep=LOCAL_EP)\n",
    "        local_w.append(mdl.state_dict())\n",
    "    # FedAvg\n",
    "    global_model.load_state_dict( average_weights(local_w, frac) )\n",
    "    print(f\"Round {rnd:2d} – mean Dice: {dice3(global_model):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
