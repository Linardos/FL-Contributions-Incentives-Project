{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vs-152/FL-Contributions-Incentives-Project/blob/main/ISO_CIFAR10_OR_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgwtkMkH37Cq",
    "outputId": "d868ac63-cbe6-4e54-92da-fc1fdab26698"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-17 14:17:32.422752392 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.6.dev2542\n",
      "Numpy version: 2.1.2\n",
      "Pytorch version: 2.8.0+cu126\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 612f3dd3cba4d73cfcea4b5329079e20aa31523d\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: 5.4.4\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.25.2\n",
      "scipy version: 1.15.3\n",
      "Pillow version: 11.0.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.23.0+cu126\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 7.0.0\n",
      "pandas version: 2.3.2\n",
      "einops version: 0.8.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Imports\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import tempfile\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.special import comb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import pulp\n",
    "import onnxruntime\n",
    "import random\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  MONAI\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    Spacingd,\n",
    "    SelectItemsd\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Custom Modules\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "from utils import *\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Device & Setup\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print_config()\n",
    "set_determinism(seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n"
     ]
    }
   ],
   "source": [
    "# Corrected conversion for FeTS labels\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    FeTS/BraTS label mapping (ints on disk): 0=background, 1=NCR/NET, 2=edema, 4=enhancing (ET)\n",
    "    Build 3-channel multi-label [TC, WT, ET]:\n",
    "      TC = (label==1) OR (label==4)\n",
    "      WT = (label==1) OR (label==2) OR (label==4)\n",
    "      ET = (label==4)\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            lab = d[key]\n",
    "            tc = torch.logical_or(lab == 1, lab == 4)\n",
    "            wt = torch.logical_or(torch.logical_or(lab == 1, lab == 2), lab == 4)\n",
    "            et = (lab == 4)\n",
    "            d[key] = torch.stack([tc, wt, et], dim=0).float()\n",
    "        return d\n",
    "\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Xg-nE1b3w-f",
    "outputId": "0490eeb3-e60d-4360-de3b-f29126c19f3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 51/51 [01:13<00:00,  1.43s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 12/12 [00:28<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train per-centre sizes: {1: 51, 2: 1, 3: 1}\n",
      "validation size: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------------------------------\n",
    "# 0. paths & meta-data (unchanged) ---------------------------\n",
    "# -----------------------------------------------------------\n",
    "BRATS_DIR = \"/mnt/d/Datasets/FETS_data/MICCAI_FeTS2022_TrainingData\"\n",
    "CSV_PATH  = f\"{BRATS_DIR}/partitioning_1.csv\"\n",
    "MODALITIES = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY  = \"seg\"\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. read partition file  ➜  { id : [subjects] } ------------\n",
    "# -----------------------------------------------------------\n",
    "part_df       = pd.read_csv(CSV_PATH)\n",
    "partition_map = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list).to_dict()\n",
    ")                               # keys are 1 … 23\n",
    "\n",
    "# VAL_CENTRES = {16, 17, 18, 19, 20, 21, 22, 23}          # ← our hold-out set\n",
    "VAL_CENTRES = {22, 23}          # ← our sanity set\n",
    "\n",
    "# split once, reuse everywhere\n",
    "train_partitions = {cid: sids for cid, sids in partition_map.items()\n",
    "                    if cid not in VAL_CENTRES}\n",
    "val_subjects     = sum((partition_map[cid] for cid in VAL_CENTRES), [])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. helper to build MONAI-style record dicts ----------------\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        sdir = f\"{BRATS_DIR}/{sid}\"\n",
    "        images = [f\"{sdir}/{sid}_{m}.nii.gz\" for m in MODALITIES]  # 4 modalities\n",
    "        recs.append({\"image\": images, \"label\": f\"{sdir}/{sid}_{LABEL_KEY}.nii.gz\"})\n",
    "    return recs\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. MONAI CacheDatasets ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "# ── client-wise training sets ───────────────────────────────\n",
    "CUT_OFF, FRAC, SEED = 3, 0.1, 42\n",
    "rng = random.Random(SEED)\n",
    "\n",
    "train_datasets = {}\n",
    "for cid, subj_ids in train_partitions.items():\n",
    "    if cid > CUT_OFF:                                    # keep your cap\n",
    "        break\n",
    "    k = max(1, int(len(subj_ids) * FRAC))                # e.g. 30 %\n",
    "    sample_ids = rng.sample(subj_ids, k)\n",
    "    train_datasets[cid] = CacheDataset(\n",
    "        build_records(sample_ids), transform=train_transform, cache_rate=1\n",
    "    )\n",
    "\n",
    "# ── single validation dataset made from *all* val subjects ─\n",
    "val_dataset = CacheDataset(\n",
    "    build_records(val_subjects), transform=val_transform, cache_rate=1\n",
    ")\n",
    "\n",
    "print(\"train per-centre sizes:\", {k: len(v) for k, v in train_datasets.items()})\n",
    "print(\"validation size:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WTUtuKlu4Ddo"
   },
   "outputs": [],
   "source": [
    "max_epochs = 300\n",
    "val_interval = 1\n",
    "VAL_AMP = True\n",
    "\n",
    "# create SegResNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "global_model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)\n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# use amp to accelerate training\n",
    "scaler = torch.GradScaler(\"cuda\")\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0de41258f7a42e39ea49553cbf25fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice before any training: (0.1479058414697647, 0.21767866611480713, 0.051870137453079224, 0.17416875064373016)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataset, device, batch_size=1,\n",
    "                   roi_size=(128, 128, 64), sw_batch_size=4):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    dice_metric.reset()\n",
    "    dice_metric_batch.reset()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)          # [B, 3, D, H, W]\n",
    "\n",
    "            logits = sliding_window_inference(\n",
    "                inputs=inputs,\n",
    "                roi_size=roi_size,\n",
    "                sw_batch_size=sw_batch_size,\n",
    "                predictor=model,                        # ← use THIS model\n",
    "            )\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            dice_metric(y_pred=preds, y=labels)\n",
    "            dice_metric_batch(y_pred=preds, y=labels)\n",
    "\n",
    "    mean_dice = dice_metric.aggregate().item()\n",
    "    metric_batch = dice_metric_batch.aggregate()\n",
    "    metric_tc = metric_batch[0].item()\n",
    "    metric_wt = metric_batch[1].item()\n",
    "    metric_et = metric_batch[2].item()\n",
    "    dice_metric.reset()\n",
    "    dice_metric_batch.reset()\n",
    "\n",
    "    return mean_dice, metric_tc, metric_wt, metric_et\n",
    "    \n",
    "print(\"Dice before any training:\", evaluate_model(global_model, val_dataset, device)) # quick sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 3 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice before any training: (0.019934942945837975, 0.017460456117987633, 0.021143466234207153, 0.02120090462267399)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Federation setup\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# train_datasets: dict[int -> MONAI CacheDataset]  (already built)\n",
    "idxs_users = list(sorted(train_datasets.keys()))\n",
    "N = len(idxs_users)\n",
    "print(f\"We got {N} clients\")\n",
    "\n",
    "# Fed hyperparams (align with your working pipeline)\n",
    "ROUNDS       = 50            # you can raise later (e.g., 100)\n",
    "LOCAL_EPOCHS = 1\n",
    "LR           = 1e-4\n",
    "BATCH        = 1\n",
    "\n",
    "# Client sizes & FedAvg fractions\n",
    "sizes     = {k: len(ds) for k, ds in train_datasets.items()}\n",
    "total_n   = sum(sizes.values())\n",
    "fractions = [sizes[k] / total_n for k in idxs_users]\n",
    "\n",
    "# Where to persist submodels / global snapshots\n",
    "submodel_dir = \"submodels\"\n",
    "os.makedirs(submodel_dir, exist_ok=True)\n",
    "submodel_file_template = os.path.join(submodel_dir, \"submodel_{}.pth\")\n",
    "global_model_path      = os.path.join(submodel_dir, \"global_model.pth\")\n",
    "best_model_path        = os.path.join(submodel_dir, \"best_metric_model.pth\")\n",
    "\n",
    "# Save initial global (round 0) – useful for baselines\n",
    "torch.save(global_model.state_dict(), global_model_path)\n",
    "\n",
    "# For later Shapley steps\n",
    "accuracy_dict = {}     # coalition -> utility (e.g., Dice on test set)\n",
    "shapley_dict  = {}     # client -> shapley value (to be filled later)\n",
    "\n",
    "# fast sanity check before any training\n",
    "print(\"Dice before any training:\", evaluate_model(global_model, val_dataset, device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvXdFSu24Iq6",
    "outputId": "76c751e1-1bbf-49a6-9803-df0517c62df5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da63ae7413f54a1697e7fdce729fb04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global rounds:   0%|                                                                              | 0/1 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df677e2af5ea42f090c3c55626391c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " clients:   0%|                                                                                   | 0/3 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11e42605da8483193c749d0928185c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "Round 01: mean-loss=0.9235 mean-Dice=0.2036  TC-Dice=0.2379  WT-Dice=0.1785  ET-Dice=0.1942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d071035651b147f29f27a0be85b7b257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results after 1 global rounds:\n",
      "|---- Val Dice(mean): 0.2036 | TC 0.2379 | WT 0.1785 | ET 0.1942\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange   # trange == tqdm(range())\n",
    "from collections import OrderedDict\n",
    "\n",
    "def average_weights(state_dicts, fractions):\n",
    "    \"\"\"\n",
    "    Federated averaging with client fractions (must sum to 1).\n",
    "    state_dicts: list of state_dicts (same keys)\n",
    "    fractions:   list of floats, same length, sum≈1\n",
    "    \"\"\"\n",
    "    avg_sd = OrderedDict()\n",
    "    for k in state_dicts[0].keys():\n",
    "        avg = 0.0\n",
    "        for sd, w in zip(state_dicts, fractions):\n",
    "            avg += sd[k] * w\n",
    "        avg_sd[k] = avg\n",
    "    return avg_sd\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# 1. one-client update (returns weights + mean loss)          │\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def local_train(model, loader, device, lr=1e-4, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a local copy of the global model on one client's DataLoader.\n",
    "    Uses your DiceLoss (multi-label, sigmoid) and full crops from transforms.\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    model.train()\n",
    "\n",
    "    # reuse your loss choice; or inline DiceLoss the same way\n",
    "    crit = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True,\n",
    "                    to_onehot_y=False, sigmoid=True).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        running = 0.0\n",
    "        for batch in loader:\n",
    "            img = batch[\"image\"].to(device)   # [B, 4, D, H, W]\n",
    "            msk = batch[\"label\"].to(device)   # [B, 3, D, H, W]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(img)               # [B, 3, D, H, W]\n",
    "            loss = crit(logits, msk)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "        epoch_losses.append(running / max(1, len(loader)))\n",
    "\n",
    "    return model.state_dict(), float(np.mean(epoch_losses))\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  FedAvg training loop (with per-client snapshots each round)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import OrderedDict\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_round = -1\n",
    "best_metrics_rounds_and_time = [[], [], []]   # best, round, seconds\n",
    "round_loss_values = []\n",
    "metric_values     = []\n",
    "metric_values_tc  = []\n",
    "metric_values_wt  = []\n",
    "metric_values_et  = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for rnd in trange(1, ROUNDS + 1, desc=\"Global rounds\", position=0, leave=True, dynamic_ncols=True):\n",
    "    local_weights, client_losses = [], []\n",
    "\n",
    "    # —— local updates per client ——\n",
    "    for cid in tqdm(idxs_users, desc=\" clients\", position=1, leave=False, total=len(idxs_users), dynamic_ncols=True):\n",
    "        loader = DataLoader(\n",
    "            train_datasets[cid], batch_size=BATCH, shuffle=True,\n",
    "            num_workers=4, pin_memory=True\n",
    "        )\n",
    "        w, loss = local_train(global_model, loader, device, lr=LR, epochs=LOCAL_EPOCHS)\n",
    "        local_weights.append(w); client_losses.append(loss)\n",
    "\n",
    "        # Persist this client's *latest* local model for Shapley / ablations\n",
    "        torch.save(w, submodel_file_template.format(cid))\n",
    "\n",
    "    # —— FedAvg (fraction-weighted) ——\n",
    "    global_model.load_state_dict(average_weights(local_weights, fractions))\n",
    "\n",
    "    # —— validation metrics on your current pipeline ——\n",
    "    mean_dice, metric_tc, metric_wt, metric_et = evaluate_model(global_model, val_dataset, device)\n",
    "    metric_values.append(mean_dice)\n",
    "    metric_values_tc.append(metric_tc)\n",
    "    metric_values_wt.append(metric_wt)\n",
    "    metric_values_et.append(metric_et)\n",
    "\n",
    "    mean_loss = float(np.mean(client_losses))\n",
    "    round_loss_values.append(mean_loss)\n",
    "\n",
    "    # —— track best & save ——\n",
    "    if mean_dice > best_metric:\n",
    "        best_metric = mean_dice\n",
    "        best_metric_round = rnd\n",
    "        best_metrics_rounds_and_time[0].append(best_metric)\n",
    "        best_metrics_rounds_and_time[1].append(best_metric_round)\n",
    "        best_metrics_rounds_and_time[2].append(time.time() - start_time)\n",
    "        torch.save(global_model.state_dict(), best_model_path)\n",
    "        print(\"saved new best metric model\")\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Round {rnd:02d}: mean-loss={mean_loss:.4f} \"\n",
    "        f\"mean-Dice={mean_dice:.4f}  \"\n",
    "        f\"TC-Dice={metric_tc:.4f}  WT-Dice={metric_wt:.4f}  ET-Dice={metric_et:.4f}\"\n",
    "    )\n",
    "\n",
    "# ── final val utility for the “grand coalition” (all clients) ─────────────\n",
    "val_mean_dice, val_tc, val_wt, val_et = evaluate_model(global_model, val_dataset, device)\n",
    "print(f\"\\nResults after {ROUNDS} global rounds:\")\n",
    "print(f\"|---- Val Dice(mean): {val_mean_dice:.4f} | TC {val_tc:.4f} | WT {val_wt:.4f} | ET {val_et:.4f}\")\n",
    "\n",
    "# Store utility for coalition = all clients (tuple keeps order deterministic)\n",
    "accuracy_dict[tuple(idxs_users)] = val_mean_dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 diff between client 1 and 2: 2.265041048515741\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# Confirm submodels differ (they should):\n",
    "import torch\n",
    "\n",
    "def l2_diff(sd1, sd2):\n",
    "    s = 0.0\n",
    "    for k in sd1:\n",
    "        s += torch.sum((sd1[k] - sd2[k])**2).item()\n",
    "    return s\n",
    "\n",
    "w1 = torch.load(submodel_file_template.format(clients[0]))\n",
    "w2 = torch.load(submodel_file_template.format(clients[1]))\n",
    "print(\"L2 diff between client 1 and 2:\", l2_diff(w1, w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03312aeb2f7e451f92558db0c88e75f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (1,): mean Val Dice=0.2055 | TC=0.2384 | WT=0.1832 | ET=0.1949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4a02b5d4a843ddb2b9d06438bf9aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (2,): mean Val Dice=0.1556 | TC=0.2242 | WT=0.0572 | ET=0.1855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd72e171acfa4872b2ff7b3fa9f60120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (3,): mean Val Dice=0.1461 | TC=0.2154 | WT=0.0467 | ET=0.1761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd2281d9ce04a949e15489bae8202d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (1, 2): mean Val Dice=0.2046 | TC=0.2382 | WT=0.1809 | ET=0.1946\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a62040534214cd980eea3aecbbb2bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (1, 3): mean Val Dice=0.2045 | TC=0.2380 | WT=0.1808 | ET=0.1945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152b9fc0a224d3fb2a2620dd1cb4ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coalition (2, 3): mean Val Dice=0.1509 | TC=0.2200 | WT=0.0516 | ET=0.1810\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m trainTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     56\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 57\u001b[0m shapley_dict \u001b[38;5;241m=\u001b[39m \u001b[43mshapley\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m shapTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     60\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/FL-Contributions-Incentives-Project/utils.py:148\u001b[0m, in \u001b[0;36mshapley\u001b[0;34m(utility, N)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m ():\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m contributor \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;66;03m# print('contributor:', contributor, key) # print check\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m         marginal_contribution \u001b[38;5;241m=\u001b[39m utility[key] \u001b[38;5;241m-\u001b[39m \u001b[43mutility\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43mcontributor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;66;03m# print('marginal:', marginal_contribution) # print check\u001b[39;00m\n\u001b[1;32m    150\u001b[0m         shapley_dict[contributor] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m marginal_contribution \u001b[38;5;241m/\u001b[39m((comb(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m*\u001b[39mN)\n",
      "\u001b[0;31mKeyError\u001b[0m: ()"
     ]
    }
   ],
   "source": [
    "# ── deterministic powerset over your sorted client IDs (exclude empty, include all) ──\n",
    "clients = list(sorted(idxs_users))                       # e.g., [1,2,3,...] or arbitrary ints\n",
    "powerset = [tuple(s) for r in range(1, len(clients)+1)   # nonempty subsets only\n",
    "            for s in combinations(clients, r)]\n",
    "\n",
    "# Build a client -> fraction map (global FedAvg fractions you already computed)\n",
    "fraction_map = {cid: frac for cid, frac in zip(clients, fractions)}\n",
    "\n",
    "# Helper: renormalize fractions within a subset so they sum to 1\n",
    "def subset_weights_and_fracs(subset):\n",
    "    w_list = [torch.load(submodel_file_template.format(cid)) for cid in subset]\n",
    "    raw_fracs = np.array([fraction_map[cid] for cid in subset], dtype=float)\n",
    "    raw_sum = float(raw_fracs.sum())\n",
    "    if raw_sum <= 0:\n",
    "        # fallback to uniform if something odd happens\n",
    "        norm_fracs = [1.0 / len(subset)] * len(subset)\n",
    "    else:\n",
    "        norm_fracs = (raw_fracs / raw_sum).tolist()\n",
    "    return w_list, norm_fracs\n",
    "\n",
    "# Evaluate every proper coalition (exclude the grand coalition at first)\n",
    "# If you want all, use `powerset`; if you want proper only, do `powerset[:-1]` as you had.\n",
    "for subset in powerset[:-1]:\n",
    "    # 1) aggregate weights\n",
    "    if len(subset) == 1:\n",
    "        subset_sd = torch.load(submodel_file_template.format(subset[0]))\n",
    "    else:\n",
    "        w_list, norm_fracs = subset_weights_and_fracs(subset)\n",
    "        subset_sd = average_weights(w_list, norm_fracs)\n",
    "\n",
    "    # 2) build a model with identical arch/buffers and load weights\n",
    "    submodel = copy.deepcopy(global_model).to(device)\n",
    "    submodel.load_state_dict(subset_sd)\n",
    "    submodel.eval()\n",
    "\n",
    "    # 3) evaluate with your current pipeline’s evaluator\n",
    "    mean_dice, metric_tc, metric_wt, metric_et = evaluate_model(submodel, val_dataset, device)\n",
    "\n",
    "    # 4) record utility\n",
    "    accuracy_dict[subset] = float(mean_dice)\n",
    "\n",
    "    print(f\"\\nCoalition {subset}: mean Val Dice={mean_dice:.4f} | TC={metric_tc:.4f} | WT={metric_wt:.4f} | ET={metric_et:.4f}\")\n",
    "\n",
    "    # free promptly\n",
    "    del submodel\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Optionally ensure the grand coalition utility is present (you stored it earlier, but just in case)\n",
    "grand = tuple(clients)\n",
    "if grand not in accuracy_dict:\n",
    "    m, tc, wt, et = evaluate_model(global_model, val_dataset, device)\n",
    "    accuracy_dict[grand] = float(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/e6b2487979ee4e2691dd68a667f2e550-pulp.mps -timeMode elapsed -branch -printingOptions all -solution /tmp/e6b2487979ee4e2691dd68a667f2e550-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 14 COLUMNS\n",
      "At line 39 RHS\n",
      "At line 49 BOUNDS\n",
      "At line 51 ENDATA\n",
      "Problem MODEL has 9 rows, 4 columns and 23 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 7 (-2) rows, 4 (0) columns and 18 (-5) elements\n",
      "0  Obj 0 Primal inf 1.2706949 (7)\n",
      "4  Obj 0.10121548\n",
      "Optimal - objective value 0.10121548\n",
      "After Postsolve, objective 0.10121548, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Optimal objective 0.1012154818 - 4 iterations time 0.002, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.01\n",
      "\n",
      "status: 1, Optimal\n",
      "objective: 0.10121548\n",
      "e: 0.101\n",
      "x(1): 0.104\n",
      "x(2): 0.054\n",
      "x(3): 0.045\n",
      "\n",
      " Grand-coalition validation utility (Dice): 0.2036\n",
      " Total Time Shapley: 388.6080s\n",
      " Total Time LC:      388.6839s\n"
     ]
    }
   ],
   "source": [
    "# utility of the empty coalition is 0 by definition\n",
    "accuracy_dict[()] = 0.0\n",
    "\n",
    "# ── Shapley & Least Core ─────────────────────────────────────────────────\n",
    "trainTime = time.time() - start_time\n",
    "start_time = time.time()\n",
    "shapley_dict = shapley(accuracy_dict, len(clients))\n",
    "shapTime = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "lc_dict = least_core(accuracy_dict, len(clients))\n",
    "LCTime = time.time() - start_time\n",
    "\n",
    "totalShapTime = trainTime + shapTime\n",
    "totalLCTime   = trainTime + LCTime\n",
    "print(f\"\\n Grand-coalition validation utility (Dice): {accuracy_dict[grand]:.4f}\")\n",
    "print(f\" Total Time Shapley: {totalShapTime:0.4f}s\")\n",
    "print(f\" Total Time LC:      {totalLCTime:0.4f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2, 3): 0.2035621553659439,\n",
       " (1,): 0.2055073380470276,\n",
       " (2,): 0.15562047064304352,\n",
       " (3,): 0.14608079195022583,\n",
       " (1, 2): 0.20459337532520294,\n",
       " (1, 3): 0.20445118844509125,\n",
       " (2, 3): 0.1508866250514984,\n",
       " (): 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapley allocation:\n",
      " client 1: 0.1040\n",
      " client 2: 0.0522\n",
      " client 3: 0.0474\n",
      "\n",
      "Least-Core allocation:\n",
      " client 1: 0.1043\n",
      " client 2: 0.0544\n",
      " client 3: 0.0449\n",
      " e (slack): 0.1012\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapley allocation:\")\n",
    "for cid, phi in shapley_dict.items():\n",
    "    print(f\" client {cid}: {phi:.4f}\")\n",
    "\n",
    "print(\"\\nLeast-Core allocation:\")\n",
    "for var in lc_dict.variables():\n",
    "    if var.name.startswith(\"x(\"):\n",
    "        print(f\" client {var.name[2:-1]}: {var.value():.4f}\")\n",
    "print(f\" e (slack): {lc_dict.variablesDict()['e'].value():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GOBqzOdQRfIe"
   },
   "outputs": [],
   "source": [
    "def stats(vector):\n",
    "    n = len(vector)\n",
    "    egal = np.array([1/n for i in range(n)])\n",
    "    normalised = np.array(vector / vector.sum())\n",
    "    msg = f'Original vector: {vector}\\n'\n",
    "    msg += f'Normalised vector: {normalised}\\n'\n",
    "    msg += f'Max Dif: {normalised.max()-normalised.min()}\\n'\n",
    "    msg += f'Distance: {np.linalg.norm(normalised-egal)}\\n'\n",
    "\n",
    "    msg += f'Budget: {vector.sum()}\\n'\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWyxrrCUwOxO",
    "outputId": "50b2f298-6572-4de7-8942-4065a3e2b0c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [0.10395151 0.05222579 0.04738486]\n",
      "Normalised vector: [0.51066224 0.25655943 0.23277833]\n",
      "Max Dif: 0.27788391257482625\n",
      "Distance: 0.21783269352317178\n",
      "Budget: 0.2035621553659439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats(np.array(list(shapley_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZ3ZJVjFJA1c",
    "outputId": "86f4a6b1-a728-45ea-83d6-7d9913b59823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [0.10429186 0.05440499 0.04486531]\n",
      "Normalised vector: [0.51233422 0.26726475 0.22040103]\n",
      "Max Dif: 0.29193318783772576\n",
      "Distance: 0.221720725590972\n",
      "Budget: 0.203562159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats(np.array([i.value() for i in lc_dict.variables()])[1:])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMNKnjfLFi/+UJW/ZI4jUCD",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ISO CIFAR10 OR FINAL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
