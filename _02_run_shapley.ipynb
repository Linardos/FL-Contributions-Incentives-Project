{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f039de47-58d0-4e66-a77a-acf67ce1b82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-12-01 21:09:27.427192054 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.6.dev2542\n",
      "Numpy version: 2.1.2\n",
      "Pytorch version: 2.8.0+cu126\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 612f3dd3cba4d73cfcea4b5329079e20aa31523d\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: 5.4.4\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.25.2\n",
      "scipy version: 1.15.3\n",
      "Pillow version: 11.0.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.23.0+cu126\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 7.0.0\n",
      "pandas version: 2.3.2\n",
      "einops version: 0.8.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train centres (top 6 by subject count):\n",
      "Partition_ID\n",
      "1     511\n",
      "4      47\n",
      "6      34\n",
      "13     35\n",
      "18    382\n",
      "21     35\n",
      "Name: Subject_ID, dtype: int64\n",
      "\n",
      "Validation centres (remaining):\n",
      "Partition_ID\n",
      "2      6\n",
      "3     15\n",
      "5     22\n",
      "7     12\n",
      "8      8\n",
      "9      4\n",
      "10     8\n",
      "11    14\n",
      "12    11\n",
      "14     6\n",
      "15    13\n",
      "16    30\n",
      "17     9\n",
      "19     4\n",
      "20    33\n",
      "22     7\n",
      "23     5\n",
      "Name: Subject_ID, dtype: int64\n",
      "\n",
      "clients: [1, 4, 6, 13, 18, 21]\n",
      "sizes: {1: 511, 4: 47, 6: 34, 13: 35, 18: 382, 21: 35}\n",
      "fractions: [0.48946360153256707, 0.045019157088122604, 0.032567049808429116, 0.033524904214559385, 0.36590038314176243, 0.033524904214559385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████| 207/207 [07:54<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation size: 207\n",
      "Loaded best global model from: submodels/best_metric_model.pth\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Imports (minimal for post-hoc Shapley eval)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "from monai.data import CacheDataset\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    NormalizeIntensityd,\n",
    "    Spacingd,\n",
    "    MapTransform,\n",
    ")\n",
    "from monai.networks.nets import SegResNet\n",
    "\n",
    "from utils import shapley, least_core  # used inside run_shapley_eval if you keep that design\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print_config()\n",
    "set_determinism(seed=0)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Label converter (same as training)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    FeTS/BraTS label mapping (ints on disk): 0=background, 1=NCR/NET, 2=edema, 4=enhancing (ET)\n",
    "    Build 3-channel multi-label [TC, WT, ET]:\n",
    "      TC = (label==1) OR (label==4)\n",
    "      WT = (label==1) OR (label==2) OR (label==4)\n",
    "      ET = (label==4)\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            lab = d[key]\n",
    "            tc = torch.logical_or(lab == 1, lab == 4)\n",
    "            wt = torch.logical_or(torch.logical_or(lab == 1, lab == 2), lab == 4)\n",
    "            et = (lab == 4)\n",
    "            d[key] = torch.stack([tc, wt, et], dim=0).float()\n",
    "        return d\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Paths & basic meta\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "BRATS_DIR = \"/mnt/d/Datasets/FETS_data/MICCAI_FeTS2022_TrainingData\"\n",
    "CSV_PATH  = f\"{BRATS_DIR}/partitioning_1.csv\"\n",
    "MODALITIES = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY  = \"seg\"\n",
    "\n",
    "TOP_K_TRAIN_SITES = 6      # must match training logic\n",
    "FRAC, SEED = 1.0, 42       # must match training script\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Partition map and train/val split (no train CacheDataset)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "part_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 1) subject counts per site\n",
    "site_counts = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .nunique()\n",
    ")\n",
    "\n",
    "# 2) pick top-K most populated sites for training\n",
    "TRAIN_CENTRES = set(\n",
    "    site_counts.sort_values(ascending=False)\n",
    "               .head(TOP_K_TRAIN_SITES)\n",
    "               .index.tolist()\n",
    ")\n",
    "\n",
    "# 3) remaining sites are validation\n",
    "VAL_CENTRES = set(site_counts.index) - TRAIN_CENTRES\n",
    "\n",
    "print(\"Train centres (top 6 by subject count):\")\n",
    "print(site_counts.loc[sorted(TRAIN_CENTRES)])\n",
    "print(\"\\nValidation centres (remaining):\")\n",
    "print(site_counts.loc[sorted(VAL_CENTRES)])\n",
    "\n",
    "# 4) map centre → subject IDs\n",
    "partition_map = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list).to_dict()\n",
    ")\n",
    "\n",
    "train_partitions = {\n",
    "    cid: sids for cid, sids in partition_map.items()\n",
    "    if cid in TRAIN_CENTRES\n",
    "}\n",
    "val_subjects = sum((partition_map[cid] for cid in VAL_CENTRES), [])\n",
    "\n",
    "# clients actually used in training\n",
    "idxs_users = sorted(train_partitions.keys())\n",
    "\n",
    "# recompute *sizes* exactly as in training: k = max(1, int(len(subj_ids) * FRAC))\n",
    "sizes = {}\n",
    "for cid in idxs_users:\n",
    "    subj_ids = train_partitions[cid]\n",
    "    k = max(1, int(len(subj_ids) * FRAC))\n",
    "    sizes[cid] = k\n",
    "\n",
    "total_n = sum(sizes.values())\n",
    "fractions = [sizes[cid] / total_n for cid in idxs_users]\n",
    "\n",
    "print(\"\\nclients:\", idxs_users)\n",
    "print(\"sizes:\", sizes)\n",
    "print(\"fractions:\", fractions)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Validation dataset only\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        sdir = f\"{BRATS_DIR}/{sid}\"\n",
    "        images = [f\"{sdir}/{sid}_{m}.nii.gz\" for m in MODALITIES]  # 4 modalities\n",
    "        recs.append({\"image\": images, \"label\": f\"{sdir}/{sid}_{LABEL_KEY}.nii.gz\"})\n",
    "    return recs\n",
    "\n",
    "val_dataset = CacheDataset(\n",
    "    build_records(val_subjects), transform=val_transform, cache_rate=1\n",
    ")\n",
    "print(\"validation size:\", len(val_dataset))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "#  Global model architecture + loading best weights\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "global_model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)\n",
    "\n",
    "submodel_dir = \"submodels\"\n",
    "submodel_file_template = os.path.join(submodel_dir, \"submodel_{}.pth\")\n",
    "best_model_path = os.path.join(submodel_dir, \"best_metric_model.pth\")\n",
    "\n",
    "global_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "global_model.eval()\n",
    "\n",
    "print(\"Loaded best global model from:\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f05af4-6cb6-4315-a3e4-1591c5dcb6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 13, 18, 21]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f794bc-595c-4f5d-b0d6-162a38220359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48946360153256707,\n",
       " 0.045019157088122604,\n",
       " 0.032567049808429116,\n",
       " 0.033524904214559385,\n",
       " 0.36590038314176243,\n",
       " 0.033524904214559385]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d356f9f8-5499-44b6-8931-381e7d0ecdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submodels/submodel_{}.pth'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel_file_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3072a468-8b4d-4b8b-a067-096112014eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapley_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8c9a5c-f362-4a49-8af4-e399aacb4b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# accuracy_dict, shapley_dict, lc_dict = shapley_eval.run_shapley_eval(\n",
    "#     global_model=global_model,\n",
    "#     val_dataset=val_dataset,\n",
    "#     idxs_users=idxs_users,                      # same list you used in training\n",
    "#     fractions=fractions,                        # same FedAvg fractions as training\n",
    "#     submodel_file_template=submodel_file_template,  # e.g. \"submodels/submodel_{}.pth\"\n",
    "#     device=device,\n",
    "#     coalition_csv=\"./logs/coalition_utilities.csv\",\n",
    "#     allocation_csv=\"./logs/allocation_summary.csv\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41e0650-b1f3-49b1-bda2-8b4d5be9cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Resume] Loaded 62 coalitions from ./logs/coalition_utilities.csv\n",
      "Skipping coalition (1,) (already evaluated).\n",
      "Skipping coalition (4,) (already evaluated).\n",
      "Skipping coalition (6,) (already evaluated).\n",
      "Skipping coalition (13,) (already evaluated).\n",
      "Skipping coalition (18,) (already evaluated).\n",
      "Skipping coalition (21,) (already evaluated).\n",
      "Skipping coalition (1, 4) (already evaluated).\n",
      "Skipping coalition (1, 6) (already evaluated).\n",
      "Skipping coalition (1, 13) (already evaluated).\n",
      "Skipping coalition (1, 18) (already evaluated).\n",
      "Skipping coalition (1, 21) (already evaluated).\n",
      "Skipping coalition (4, 6) (already evaluated).\n",
      "Skipping coalition (4, 13) (already evaluated).\n",
      "Skipping coalition (4, 18) (already evaluated).\n",
      "Skipping coalition (4, 21) (already evaluated).\n",
      "Skipping coalition (6, 13) (already evaluated).\n",
      "Skipping coalition (6, 18) (already evaluated).\n",
      "Skipping coalition (6, 21) (already evaluated).\n",
      "Skipping coalition (13, 18) (already evaluated).\n",
      "Skipping coalition (13, 21) (already evaluated).\n",
      "Skipping coalition (18, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 6) (already evaluated).\n",
      "Skipping coalition (1, 4, 13) (already evaluated).\n",
      "Skipping coalition (1, 4, 18) (already evaluated).\n",
      "Skipping coalition (1, 4, 21) (already evaluated).\n",
      "Skipping coalition (1, 6, 13) (already evaluated).\n",
      "Skipping coalition (1, 6, 18) (already evaluated).\n",
      "Skipping coalition (1, 6, 21) (already evaluated).\n",
      "Skipping coalition (1, 13, 18) (already evaluated).\n",
      "Skipping coalition (1, 13, 21) (already evaluated).\n",
      "Skipping coalition (1, 18, 21) (already evaluated).\n",
      "Skipping coalition (4, 6, 13) (already evaluated).\n",
      "Skipping coalition (4, 6, 18) (already evaluated).\n",
      "Skipping coalition (4, 6, 21) (already evaluated).\n",
      "Skipping coalition (4, 13, 18) (already evaluated).\n",
      "Skipping coalition (4, 13, 21) (already evaluated).\n",
      "Skipping coalition (4, 18, 21) (already evaluated).\n",
      "Skipping coalition (6, 13, 18) (already evaluated).\n",
      "Skipping coalition (6, 13, 21) (already evaluated).\n",
      "Skipping coalition (6, 18, 21) (already evaluated).\n",
      "Skipping coalition (13, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 13) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 18) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 13, 18) (already evaluated).\n",
      "Skipping coalition (1, 4, 13, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 6, 13, 18) (already evaluated).\n",
      "Skipping coalition (1, 6, 13, 21) (already evaluated).\n",
      "Skipping coalition (1, 6, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 13, 18, 21) (already evaluated).\n",
      "Skipping coalition (4, 6, 13, 18) (already evaluated).\n",
      "Skipping coalition (4, 6, 13, 21) (already evaluated).\n",
      "Skipping coalition (4, 6, 18, 21) (already evaluated).\n",
      "Skipping coalition (4, 13, 18, 21) (already evaluated).\n",
      "Skipping coalition (6, 13, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 13, 18) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 13, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 6, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 4, 13, 18, 21) (already evaluated).\n",
      "Skipping coalition (1, 6, 13, 18, 21) (already evaluated).\n",
      "Skipping coalition (4, 6, 13, 18, 21) (already evaluated).\n",
      "Evaluating grand coalition...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf937f3a27b4362809656e1f61fb567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total coalition eval time: 95.1772s\n",
      " Grand-coalition validation utility (Dice): 0.7899\n",
      "\n",
      "[Saved] Coalition utilities → ./logs/coalition_utilities.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Long, resumable coalition evaluation\n",
    "accuracy_dict = compute_coalition_utilities(\n",
    "    global_model=global_model,\n",
    "    val_dataset=val_dataset,\n",
    "    idxs_users=idxs_users,\n",
    "    fractions=fractions,\n",
    "    submodel_file_template=\"submodels/submodel_{}.pth\",\n",
    "    device=device,\n",
    "    coalition_csv=\"./logs/coalition_utilities.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89a53b5-8155-45e7-a9dc-808f03ecd84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contributor: 1 (1,)\n",
      "marginal: 0.7209593653678894\n",
      "contributor: 4 (4,)\n",
      "marginal: 0.7006985545158386\n",
      "contributor: 6 (6,)\n",
      "marginal: 0.7113056182861328\n",
      "contributor: 13 (13,)\n",
      "marginal: 0.707489013671875\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 2. Fast Shapley/LC — can be re-run anytime from the CSV\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy_dict, shapley_dict, lc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrun_shapley_from_coalitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoalition_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs/coalition_utilities.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallocation_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs/allocation_summary.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FL-Contributions-Incentives-Project/shapley_eval.py:329\u001b[0m, in \u001b[0;36mrun_shapley_from_coalitions\u001b[0;34m(coalition_csv, allocation_csv)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# ── Shapley & Least Core ────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m    328\u001b[0m shap_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 329\u001b[0m shapley_dict \u001b[38;5;241m=\u001b[39m \u001b[43mshapley\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m shapTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m shap_start\n\u001b[1;32m    332\u001b[0m lc_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/FL-Contributions-Incentives-Project/utils.py:150\u001b[0m, in \u001b[0;36mshapley\u001b[0;34m(utility, N)\u001b[0m\n\u001b[1;32m    148\u001b[0m             marginal_contribution \u001b[38;5;241m=\u001b[39m utility[key] \u001b[38;5;241m-\u001b[39m utility[\u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m!=\u001b[39mcontributor)]\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarginal:\u001b[39m\u001b[38;5;124m'\u001b[39m, marginal_contribution) \u001b[38;5;66;03m# print check\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m             shapley_dict[contributor] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m marginal_contribution \u001b[38;5;241m/\u001b[39m((comb(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m*\u001b[39mN)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shapley_dict\n",
      "\u001b[0;31mKeyError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Fast Shapley/LC — can be re-run anytime from the CSV\n",
    "accuracy_dict, shapley_dict, lc_dict = run_shapley_from_coalitions(\n",
    "    coalition_csv=\"./logs/coalition_utilities.csv\",\n",
    "    allocation_csv=\"./logs/allocation_summary.csv\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
