{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vs-152/FL-Contributions-Incentives-Project/blob/main/ISO_CIFAR10_OR_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgwtkMkH37Cq",
    "outputId": "d868ac63-cbe6-4e54-92da-fc1fdab26698"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pulp\n",
    "import copy\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from itertools import chain, combinations\n",
    "from tqdm import tqdm\n",
    "from scipy.special import comb\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "a5hHwk9S3-zy"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Xg-nE1b3w-f",
    "outputId": "0490eeb3-e60d-4360-de3b-f29126c19f3f"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 0.  Paths & meta-data\n",
    "# -----------------------------------------------------------\n",
    "import glob, nibabel as nib, pandas as pd\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Orientationd, ScaleIntensityd,\n",
    "    RandFlipd, RandSpatialCropd, Compose, SelectItemsd\n",
    ")\n",
    "\n",
    "BRATS_DIR   = \"/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData\"\n",
    "VAL_DIR     = \"/home/locolinux2/datasets/MICCAI_FeTS2022_ValidationData\"\n",
    "CSV_PATH    = f\"{BRATS_DIR}/partitioning_1.csv\"     # pick 1, 2 … or sanity\n",
    "MODALITIES  = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY   = \"seg\"  # BraTS tumour mask filename ending\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1.  Read partition file → mapping   {client_id: [subjIDs]}\n",
    "# -----------------------------------------------------------\n",
    "part_df          = pd.read_csv(CSV_PATH)\n",
    "partition_map    = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list)\n",
    "           .to_dict()\n",
    ")\n",
    "NUM_CLIENTS = len(partition_map)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2.  Build a list of dicts – one per subject\n",
    "# -----------------------------------------------------------\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        subj_dir = f\"{BRATS_DIR}/{sid}\"\n",
    "        rec = {m: f\"{subj_dir}/{sid}_{m}.nii.gz\"\n",
    "               for m in MODALITIES}\n",
    "        rec[\"seg\"] = f\"{subj_dir}/{sid}_{LABEL_KEY}.nii.gz\"\n",
    "        recs.append(rec)\n",
    "    return recs\n",
    "\n",
    "def build_val_records(val_dir):\n",
    "    subjects = sorted(glob.glob(f\"{val_dir}/FeTS2022_*_flair.nii.gz\"))\n",
    "    recs = []\n",
    "    for flair_path in subjects:\n",
    "        sid = flair_path.split(\"/\")[-1].split(\"_flair\")[0]\n",
    "        subj_dir = f\"{val_dir}/{sid}\"\n",
    "        rec = {m: f\"{subj_dir}/{sid}_{m}.nii.gz\" for m in MODALITIES}\n",
    "        recs.append(rec)\n",
    "    return recs\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3.  MONAI transform pipelines  (fixed)\n",
    "# -----------------------------------------------------------\n",
    "IMG_KEYS   = [m for m in MODALITIES]\n",
    "ALL_KEYS   = IMG_KEYS + [LABEL_KEY]\n",
    "\n",
    "train_tf = Compose([\n",
    "    LoadImaged(keys=ALL_KEYS),\n",
    "    EnsureChannelFirstd(keys=ALL_KEYS),\n",
    "    Orientationd(keys=ALL_KEYS, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=ALL_KEYS, minv=-1.0, maxv=1.0), # scale to [-1,1]. Diffusion Models do better if centered on a 0 mean\n",
    "    SelectItemsd(keys=ALL_KEYS),\n",
    "])\n",
    "\n",
    "val_tf = Compose([\n",
    "    LoadImaged(keys=MODALITIES),\n",
    "    EnsureChannelFirstd(keys=MODALITIES),\n",
    "    Orientationd(keys=MODALITIES, axcodes=\"RAS\"),\n",
    "    ScaleIntensityd(keys=MODALITIES, minv=-1.0, maxv=1.0),\n",
    "    SelectItemsd(keys=MODALITIES),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, ['FeTS2022_01341', 'FeTS2022_01333', 'FeTS2022_01077', 'FeTS2022_01054', 'FeTS2022_00285', 'FeTS2022_01308', 'FeTS2022_01363', 'FeTS2022_01091', 'FeTS2022_01273', 'FeTS2022_01108', 'FeTS2022_01255', 'FeTS2022_01301', 'FeTS2022_00219', 'FeTS2022_00380', 'FeTS2022_01349', 'FeTS2022_00251', 'FeTS2022_01276', 'FeTS2022_01407', 'FeTS2022_01344', 'FeTS2022_01405', 'FeTS2022_00218', 'FeTS2022_01327', 'FeTS2022_01252', 'FeTS2022_01132', 'FeTS2022_01036', 'FeTS2022_01039', 'FeTS2022_01366', 'FeTS2022_00262', 'FeTS2022_01279', 'FeTS2022_00839', 'FeTS2022_01322', 'FeTS2022_00389', 'FeTS2022_00390', 'FeTS2022_00431', 'FeTS2022_00222', 'FeTS2022_00373', 'FeTS2022_00288', 'FeTS2022_00284', 'FeTS2022_01088', 'FeTS2022_00311', 'FeTS2022_00387', 'FeTS2022_00258', 'FeTS2022_01389', 'FeTS2022_00321', 'FeTS2022_01249', 'FeTS2022_01230', 'FeTS2022_00836', 'FeTS2022_00348', 'FeTS2022_01205', 'FeTS2022_00246', 'FeTS2022_00314', 'FeTS2022_01404', 'FeTS2022_01102', 'FeTS2022_00379', 'FeTS2022_01395', 'FeTS2022_00155', 'FeTS2022_00170', 'FeTS2022_01264', 'FeTS2022_00837', 'FeTS2022_01372', 'FeTS2022_00341', 'FeTS2022_01257', 'FeTS2022_00329', 'FeTS2022_00425', 'FeTS2022_01350', 'FeTS2022_01247', 'FeTS2022_01234', 'FeTS2022_00331', 'FeTS2022_01128', 'FeTS2022_01365', 'FeTS2022_00221', 'FeTS2022_00298', 'FeTS2022_00227', 'FeTS2022_01204', 'FeTS2022_00204', 'FeTS2022_01399', 'FeTS2022_00377', 'FeTS2022_00343', 'FeTS2022_00280', 'FeTS2022_01347', 'FeTS2022_00210', 'FeTS2022_01117', 'FeTS2022_01275', 'FeTS2022_01034', 'FeTS2022_00162', 'FeTS2022_01340', 'FeTS2022_01212', 'FeTS2022_01220', 'FeTS2022_00419', 'FeTS2022_00340', 'FeTS2022_00296', 'FeTS2022_01208', 'FeTS2022_01064', 'FeTS2022_00433', 'FeTS2022_01050', 'FeTS2022_01278', 'FeTS2022_00293', 'FeTS2022_00206', 'FeTS2022_00356', 'FeTS2022_00376', 'FeTS2022_00316', 'FeTS2022_00403', 'FeTS2022_01348', 'FeTS2022_00192', 'FeTS2022_00313', 'FeTS2022_01240', 'FeTS2022_01222', 'FeTS2022_00344', 'FeTS2022_00332', 'FeTS2022_00292', 'FeTS2022_01392', 'FeTS2022_00220', 'FeTS2022_00378', 'FeTS2022_01130', 'FeTS2022_01106', 'FeTS2022_01295', 'FeTS2022_01409', 'FeTS2022_01057', 'FeTS2022_01068', 'FeTS2022_00320', 'FeTS2022_00346', 'FeTS2022_01001', 'FeTS2022_01207', 'FeTS2022_01137', 'FeTS2022_01318', 'FeTS2022_00289', 'FeTS2022_00157', 'FeTS2022_01224', 'FeTS2022_01367', 'FeTS2022_01382', 'FeTS2022_00309', 'FeTS2022_01008', 'FeTS2022_01059', 'FeTS2022_01271', 'FeTS2022_01110', 'FeTS2022_01398', 'FeTS2022_01119', 'FeTS2022_00209', 'FeTS2022_01274', 'FeTS2022_01124', 'FeTS2022_00241', 'FeTS2022_00152', 'FeTS2022_01131', 'FeTS2022_01353', 'FeTS2022_00352', 'FeTS2022_01133', 'FeTS2022_01084', 'FeTS2022_00441', 'FeTS2022_01268', 'FeTS2022_01210', 'FeTS2022_01375', 'FeTS2022_00236', 'FeTS2022_01218', 'FeTS2022_01408', 'FeTS2022_00274', 'FeTS2022_01118', 'FeTS2022_01213', 'FeTS2022_01310', 'FeTS2022_00194', 'FeTS2022_00392', 'FeTS2022_00334', 'FeTS2022_00270', 'FeTS2022_01359', 'FeTS2022_01364', 'FeTS2022_01336', 'FeTS2022_01272', 'FeTS2022_01090', 'FeTS2022_00412', 'FeTS2022_00228', 'FeTS2022_00410', 'FeTS2022_01239', 'FeTS2022_01010', 'FeTS2022_01394', 'FeTS2022_00282', 'FeTS2022_00237', 'FeTS2022_01390', 'FeTS2022_00382', 'FeTS2022_00188', 'FeTS2022_01211', 'FeTS2022_01376', 'FeTS2022_01243', 'FeTS2022_01330', 'FeTS2022_00253', 'FeTS2022_01329', 'FeTS2022_01306', 'FeTS2022_01081', 'FeTS2022_01369', 'FeTS2022_01048', 'FeTS2022_00328', 'FeTS2022_00291', 'FeTS2022_01049', 'FeTS2022_01263', 'FeTS2022_00317', 'FeTS2022_00305', 'FeTS2022_01265', 'FeTS2022_00238', 'FeTS2022_00423', 'FeTS2022_01127', 'FeTS2022_01379', 'FeTS2022_01258', 'FeTS2022_00299', 'FeTS2022_01334', 'FeTS2022_00350', 'FeTS2022_01109', 'FeTS2022_01352', 'FeTS2022_01055', 'FeTS2022_00167', 'FeTS2022_01354', 'FeTS2022_01231', 'FeTS2022_00185', 'FeTS2022_00306', 'FeTS2022_00171', 'FeTS2022_01261', 'FeTS2022_01345', 'FeTS2022_01397', 'FeTS2022_00399', 'FeTS2022_01319', 'FeTS2022_01250', 'FeTS2022_01097', 'FeTS2022_01229', 'FeTS2022_01393', 'FeTS2022_00430', 'FeTS2022_01203', 'FeTS2022_01309', 'FeTS2022_01342', 'FeTS2022_01223', 'FeTS2022_00239', 'FeTS2022_00275', 'FeTS2022_00406', 'FeTS2022_01116', 'FeTS2022_01380', 'FeTS2022_00214', 'FeTS2022_00195', 'FeTS2022_01314', 'FeTS2022_01113', 'FeTS2022_00193', 'FeTS2022_01259', 'FeTS2022_00386', 'FeTS2022_00834', 'FeTS2022_01227', 'FeTS2022_01277', 'FeTS2022_00283', 'FeTS2022_01099', 'FeTS2022_00212', 'FeTS2022_00165', 'FeTS2022_01332', 'FeTS2022_00364', 'FeTS2022_01129', 'FeTS2022_00301', 'FeTS2022_01402', 'FeTS2022_00199', 'FeTS2022_01066', 'FeTS2022_01107', 'FeTS2022_01337', 'FeTS2022_00230', 'FeTS2022_01114', 'FeTS2022_01294', 'FeTS2022_01370', 'FeTS2022_01269', 'FeTS2022_01043', 'FeTS2022_00359', 'FeTS2022_01004', 'FeTS2022_00286', 'FeTS2022_01038', 'FeTS2022_00370', 'FeTS2022_00184', 'FeTS2022_00360', 'FeTS2022_01123', 'FeTS2022_01237', 'FeTS2022_01086', 'FeTS2022_00231', 'FeTS2022_00353', 'FeTS2022_01254', 'FeTS2022_01373', 'FeTS2022_01100', 'FeTS2022_01214', 'FeTS2022_01242', 'FeTS2022_01115', 'FeTS2022_01331', 'FeTS2022_00391', 'FeTS2022_01312', 'FeTS2022_00324', 'FeTS2022_01080', 'FeTS2022_00371', 'FeTS2022_01396', 'FeTS2022_00339', 'FeTS2022_00260', 'FeTS2022_00243', 'FeTS2022_00233', 'FeTS2022_01323', 'FeTS2022_01248', 'FeTS2022_00263', 'FeTS2022_00347', 'FeTS2022_01233', 'FeTS2022_00367', 'FeTS2022_01051', 'FeTS2022_01126', 'FeTS2022_01267', 'FeTS2022_00383', 'FeTS2022_01357', 'FeTS2022_00413', 'FeTS2022_01287', 'FeTS2022_00349', 'FeTS2022_01244', 'FeTS2022_01041', 'FeTS2022_01236', 'FeTS2022_01245', 'FeTS2022_01383', 'FeTS2022_00196', 'FeTS2022_01387', 'FeTS2022_00297', 'FeTS2022_01103', 'FeTS2022_01098', 'FeTS2022_01410', 'FeTS2022_00440', 'FeTS2022_01305', 'FeTS2022_01304', 'FeTS2022_01074', 'FeTS2022_01046', 'FeTS2022_01226', 'FeTS2022_01253', 'FeTS2022_01040', 'FeTS2022_00269', 'FeTS2022_00310', 'FeTS2022_01056', 'FeTS2022_01311', 'FeTS2022_01338', 'FeTS2022_00166', 'FeTS2022_00327', 'FeTS2022_00254', 'FeTS2022_01000', 'FeTS2022_00259', 'FeTS2022_01134', 'FeTS2022_01104', 'FeTS2022_01232', 'FeTS2022_01286', 'FeTS2022_01052', 'FeTS2022_01217', 'FeTS2022_01238', 'FeTS2022_00154', 'FeTS2022_00395', 'FeTS2022_00267', 'FeTS2022_00366', 'FeTS2022_00351', 'FeTS2022_00159', 'FeTS2022_00131', 'FeTS2022_01246', 'FeTS2022_01060', 'FeTS2022_01087', 'FeTS2022_00250', 'FeTS2022_00234', 'FeTS2022_01058', 'FeTS2022_00235', 'FeTS2022_00203', 'FeTS2022_00414', 'FeTS2022_01285', 'FeTS2022_01071', 'FeTS2022_01111', 'FeTS2022_01377', 'FeTS2022_01355', 'FeTS2022_01384', 'FeTS2022_01120', 'FeTS2022_01082', 'FeTS2022_01076', 'FeTS2022_01072', 'FeTS2022_00303', 'FeTS2022_00436', 'FeTS2022_01361', 'FeTS2022_01073', 'FeTS2022_00338', 'FeTS2022_01351', 'FeTS2022_00273', 'FeTS2022_00186', 'FeTS2022_00290', 'FeTS2022_01381', 'FeTS2022_01083', 'FeTS2022_00409', 'FeTS2022_00281', 'FeTS2022_00840', 'FeTS2022_00407', 'FeTS2022_01094', 'FeTS2022_01328', 'FeTS2022_01078', 'FeTS2022_00312', 'FeTS2022_01235', 'FeTS2022_01288', 'FeTS2022_01391', 'FeTS2022_01215', 'FeTS2022_00160', 'FeTS2022_00421', 'FeTS2022_01317', 'FeTS2022_01216', 'FeTS2022_00178', 'FeTS2022_00838', 'FeTS2022_01321', 'FeTS2022_01037', 'FeTS2022_00176', 'FeTS2022_01293', 'FeTS2022_01219', 'FeTS2022_01260', 'FeTS2022_01339', 'FeTS2022_01325', 'FeTS2022_00249', 'FeTS2022_01241', 'FeTS2022_00211', 'FeTS2022_01105', 'FeTS2022_01138', 'FeTS2022_00261', 'FeTS2022_01316', 'FeTS2022_01315', 'FeTS2022_01256', 'FeTS2022_00191', 'FeTS2022_01069', 'FeTS2022_01062', 'FeTS2022_01135', 'FeTS2022_00207', 'FeTS2022_00401', 'FeTS2022_00172', 'FeTS2022_01085', 'FeTS2022_00247', 'FeTS2022_01206', 'FeTS2022_01356', 'FeTS2022_00325', 'FeTS2022_00429', 'FeTS2022_01122', 'FeTS2022_01374', 'FeTS2022_00156', 'FeTS2022_01075', 'FeTS2022_01362', 'FeTS2022_01251', 'FeTS2022_00405', 'FeTS2022_01047', 'FeTS2022_00240', 'FeTS2022_00336', 'FeTS2022_01092', 'FeTS2022_01403', 'FeTS2022_01385', 'FeTS2022_01096', 'FeTS2022_00426', 'FeTS2022_00201', 'FeTS2022_01335', 'FeTS2022_00404', 'FeTS2022_00322', 'FeTS2022_00294', 'FeTS2022_01070', 'FeTS2022_01225', 'FeTS2022_01067', 'FeTS2022_00375', 'FeTS2022_00158', 'FeTS2022_00177', 'FeTS2022_00271', 'FeTS2022_01388', 'FeTS2022_01053', 'FeTS2022_01042', 'FeTS2022_01400', 'FeTS2022_00183', 'FeTS2022_01358', 'FeTS2022_01266', 'FeTS2022_01360', 'FeTS2022_00304', 'FeTS2022_01065', 'FeTS2022_01093', 'FeTS2022_00397', 'FeTS2022_01262', 'FeTS2022_00217', 'FeTS2022_01401', 'FeTS2022_01125', 'FeTS2022_01406', 'FeTS2022_01343', 'FeTS2022_01346', 'FeTS2022_01089', 'FeTS2022_00216', 'FeTS2022_01061', 'FeTS2022_01299', 'FeTS2022_00242', 'FeTS2022_01112', 'FeTS2022_00300', 'FeTS2022_01280', 'FeTS2022_00187', 'FeTS2022_00318', 'FeTS2022_01371', 'FeTS2022_01378', 'FeTS2022_00418', 'FeTS2022_01121', 'FeTS2022_01136', 'FeTS2022_00266', 'FeTS2022_01221', 'FeTS2022_01307', 'FeTS2022_01386', 'FeTS2022_00432', 'FeTS2022_01101', 'FeTS2022_01228', 'FeTS2022_01313', 'FeTS2022_01209', 'FeTS2022_00388', 'FeTS2022_01270', 'FeTS2022_01044', 'FeTS2022_00417', 'FeTS2022_01063', 'FeTS2022_01368', 'FeTS2022_00369', 'FeTS2022_01095', 'FeTS2022_00416', 'FeTS2022_00400', 'FeTS2022_01045', 'FeTS2022_01202', 'FeTS2022_01326', 'FeTS2022_01079', 'FeTS2022_00402', 'FeTS2022_01320', 'FeTS2022_01324']), (2, ['FeTS2022_01412', 'FeTS2022_01415', 'FeTS2022_01411', 'FeTS2022_01414', 'FeTS2022_01413', 'FeTS2022_01416']), (3, ['FeTS2022_01439', 'FeTS2022_01435', 'FeTS2022_01434', 'FeTS2022_01440', 'FeTS2022_01431', 'FeTS2022_01437', 'FeTS2022_01436', 'FeTS2022_01433', 'FeTS2022_01438', 'FeTS2022_01426', 'FeTS2022_01427', 'FeTS2022_01428', 'FeTS2022_01429', 'FeTS2022_01432', 'FeTS2022_01430']), (4, ['FeTS2022_01152', 'FeTS2022_01178', 'FeTS2022_01186', 'FeTS2022_01184', 'FeTS2022_01181', 'FeTS2022_01187', 'FeTS2022_01168', 'FeTS2022_01196', 'FeTS2022_01173', 'FeTS2022_01176', 'FeTS2022_01200', 'FeTS2022_00565', 'FeTS2022_01193', 'FeTS2022_01174', 'FeTS2022_01662', 'FeTS2022_01660', 'FeTS2022_01201', 'FeTS2022_01167', 'FeTS2022_01170', 'FeTS2022_01179', 'FeTS2022_01185', 'FeTS2022_01197', 'FeTS2022_01172', 'FeTS2022_01189', 'FeTS2022_00563', 'FeTS2022_01180', 'FeTS2022_01198', 'FeTS2022_01183', 'FeTS2022_01151', 'FeTS2022_01195', 'FeTS2022_01657', 'FeTS2022_01194', 'FeTS2022_01191', 'FeTS2022_01169', 'FeTS2022_01171', 'FeTS2022_00561', 'FeTS2022_01659', 'FeTS2022_01661', 'FeTS2022_01190', 'FeTS2022_01188', 'FeTS2022_01199', 'FeTS2022_01658', 'FeTS2022_01192', 'FeTS2022_01175', 'FeTS2022_01182', 'FeTS2022_01537', 'FeTS2022_01177']), (5, ['FeTS2022_00102', 'FeTS2022_00149', 'FeTS2022_01290', 'FeTS2022_00113', 'FeTS2022_01009', 'FeTS2022_01007', 'FeTS2022_01002', 'FeTS2022_00139', 'FeTS2022_01292', 'FeTS2022_00100', 'FeTS2022_01289', 'FeTS2022_01291', 'FeTS2022_01005', 'FeTS2022_01282', 'FeTS2022_01003', 'FeTS2022_00109', 'FeTS2022_01283', 'FeTS2022_00999', 'FeTS2022_01281', 'FeTS2022_01284', 'FeTS2022_00151', 'FeTS2022_00123']), (6, ['FeTS2022_01451', 'FeTS2022_01453', 'FeTS2022_01452', 'FeTS2022_00831', 'FeTS2022_01448', 'FeTS2022_01300', 'FeTS2022_01443', 'FeTS2022_00136', 'FeTS2022_01454', 'FeTS2022_00144', 'FeTS2022_00121', 'FeTS2022_01297', 'FeTS2022_00133', 'FeTS2022_01447', 'FeTS2022_00142', 'FeTS2022_01450', 'FeTS2022_00120', 'FeTS2022_01298', 'FeTS2022_01449', 'FeTS2022_01442', 'FeTS2022_01446', 'FeTS2022_01303', 'FeTS2022_01296', 'FeTS2022_00132', 'FeTS2022_01441', 'FeTS2022_01445', 'FeTS2022_01302', 'FeTS2022_00143', 'FeTS2022_00105', 'FeTS2022_01444', 'FeTS2022_00147', 'FeTS2022_01455', 'FeTS2022_00146', 'FeTS2022_00137']), (7, ['FeTS2022_01459', 'FeTS2022_01464', 'FeTS2022_01458', 'FeTS2022_01457', 'FeTS2022_01461', 'FeTS2022_01456', 'FeTS2022_01460', 'FeTS2022_01462', 'FeTS2022_01466', 'FeTS2022_01465', 'FeTS2022_01463', 'FeTS2022_01467']), (8, ['FeTS2022_00140', 'FeTS2022_01469', 'FeTS2022_01468', 'FeTS2022_01470', 'FeTS2022_00104', 'FeTS2022_00110', 'FeTS2022_00112', 'FeTS2022_00128']), (9, ['FeTS2022_00134', 'FeTS2022_00150', 'FeTS2022_00116', 'FeTS2022_01471']), (10, ['FeTS2022_01472', 'FeTS2022_00117', 'FeTS2022_00130', 'FeTS2022_00138', 'FeTS2022_01473', 'FeTS2022_00111', 'FeTS2022_00124', 'FeTS2022_00106']), (11, ['FeTS2022_00122', 'FeTS2022_00148', 'FeTS2022_01474', 'FeTS2022_00108', 'FeTS2022_01144', 'FeTS2022_00107', 'FeTS2022_01140', 'FeTS2022_01146', 'FeTS2022_01145', 'FeTS2022_01139', 'FeTS2022_01141', 'FeTS2022_01142', 'FeTS2022_01143', 'FeTS2022_01475']), (12, ['FeTS2022_01482', 'FeTS2022_01480', 'FeTS2022_01485', 'FeTS2022_01476', 'FeTS2022_01481', 'FeTS2022_01483', 'FeTS2022_01486', 'FeTS2022_01484', 'FeTS2022_01479', 'FeTS2022_01477', 'FeTS2022_01478']), (13, ['FeTS2022_01491', 'FeTS2022_01500', 'FeTS2022_01519', 'FeTS2022_01516', 'FeTS2022_01509', 'FeTS2022_01520', 'FeTS2022_01508', 'FeTS2022_01503', 'FeTS2022_01488', 'FeTS2022_01492', 'FeTS2022_01502', 'FeTS2022_01493', 'FeTS2022_01497', 'FeTS2022_01499', 'FeTS2022_01487', 'FeTS2022_01505', 'FeTS2022_01504', 'FeTS2022_01490', 'FeTS2022_01507', 'FeTS2022_01510', 'FeTS2022_01512', 'FeTS2022_01514', 'FeTS2022_01517', 'FeTS2022_01501', 'FeTS2022_01518', 'FeTS2022_01506', 'FeTS2022_01515', 'FeTS2022_01511', 'FeTS2022_01494', 'FeTS2022_01489', 'FeTS2022_01513', 'FeTS2022_01496', 'FeTS2022_01495', 'FeTS2022_01521', 'FeTS2022_01498']), (14, ['FeTS2022_01522', 'FeTS2022_01525', 'FeTS2022_01526', 'FeTS2022_01527', 'FeTS2022_01524', 'FeTS2022_01523']), (15, ['FeTS2022_01530', 'FeTS2022_01536', 'FeTS2022_01535', 'FeTS2022_01663', 'FeTS2022_01534', 'FeTS2022_01529', 'FeTS2022_01531', 'FeTS2022_01666', 'FeTS2022_01665', 'FeTS2022_01532', 'FeTS2022_01664', 'FeTS2022_01528', 'FeTS2022_01533']), (16, ['FeTS2022_00584', 'FeTS2022_00567', 'FeTS2022_00571', 'FeTS2022_00582', 'FeTS2022_00570', 'FeTS2022_00594', 'FeTS2022_00597', 'FeTS2022_00596', 'FeTS2022_00576', 'FeTS2022_00572', 'FeTS2022_00115', 'FeTS2022_00593', 'FeTS2022_00588', 'FeTS2022_00598', 'FeTS2022_00589', 'FeTS2022_00574', 'FeTS2022_00586', 'FeTS2022_00579', 'FeTS2022_00590', 'FeTS2022_00599', 'FeTS2022_00577', 'FeTS2022_00575', 'FeTS2022_00581', 'FeTS2022_00591', 'FeTS2022_00569', 'FeTS2022_00587', 'FeTS2022_00580', 'FeTS2022_00583', 'FeTS2022_00578', 'FeTS2022_00568']), (17, ['FeTS2022_01423', 'FeTS2022_01420', 'FeTS2022_01422', 'FeTS2022_01417', 'FeTS2022_01421', 'FeTS2022_01424', 'FeTS2022_01418', 'FeTS2022_01425', 'FeTS2022_01419']), (18, ['FeTS2022_01628', 'FeTS2022_01615', 'FeTS2022_01035', 'FeTS2022_00732', 'FeTS2022_00753', 'FeTS2022_01620', 'FeTS2022_01637', 'FeTS2022_01594', 'FeTS2022_00530', 'FeTS2022_00772', 'FeTS2022_01580', 'FeTS2022_00731', 'FeTS2022_00540', 'FeTS2022_00464', 'FeTS2022_01622', 'FeTS2022_01154', 'FeTS2022_01559', 'FeTS2022_00729', 'FeTS2022_00708', 'FeTS2022_00044', 'FeTS2022_00705', 'FeTS2022_00645', 'FeTS2022_01640', 'FeTS2022_00008', 'FeTS2022_00746', 'FeTS2022_01551', 'FeTS2022_01610', 'FeTS2022_00061', 'FeTS2022_00642', 'FeTS2022_00675', 'FeTS2022_01651', 'FeTS2022_00651', 'FeTS2022_00626', 'FeTS2022_00028', 'FeTS2022_01557', 'FeTS2022_01616', 'FeTS2022_00684', 'FeTS2022_01538', 'FeTS2022_01647', 'FeTS2022_00688', 'FeTS2022_00737', 'FeTS2022_00063', 'FeTS2022_00758', 'FeTS2022_01159', 'FeTS2022_00615', 'FeTS2022_00621', 'FeTS2022_01543', 'FeTS2022_01560', 'FeTS2022_00058', 'FeTS2022_00009', 'FeTS2022_00544', 'FeTS2022_01611', 'FeTS2022_00485', 'FeTS2022_00735', 'FeTS2022_00659', 'FeTS2022_00025', 'FeTS2022_00550', 'FeTS2022_01599', 'FeTS2022_00636', 'FeTS2022_01644', 'FeTS2022_00716', 'FeTS2022_00641', 'FeTS2022_01624', 'FeTS2022_00547', 'FeTS2022_00046', 'FeTS2022_00728', 'FeTS2022_00045', 'FeTS2022_00493', 'FeTS2022_00089', 'FeTS2022_00622', 'FeTS2022_01643', 'FeTS2022_00602', 'FeTS2022_00035', 'FeTS2022_01545', 'FeTS2022_00014', 'FeTS2022_01566', 'FeTS2022_00066', 'FeTS2022_01614', 'FeTS2022_01591', 'FeTS2022_00514', 'FeTS2022_01588', 'FeTS2022_00520', 'FeTS2022_01556', 'FeTS2022_00097', 'FeTS2022_00555', 'FeTS2022_00736', 'FeTS2022_00639', 'FeTS2022_00479', 'FeTS2022_01550', 'FeTS2022_01592', 'FeTS2022_01626', 'FeTS2022_00557', 'FeTS2022_00496', 'FeTS2022_00778', 'FeTS2022_01561', 'FeTS2022_00690', 'FeTS2022_00750', 'FeTS2022_01586', 'FeTS2022_01549', 'FeTS2022_01555', 'FeTS2022_01612', 'FeTS2022_01600', 'FeTS2022_01629', 'FeTS2022_01656', 'FeTS2022_00500', 'FeTS2022_00529', 'FeTS2022_00628', 'FeTS2022_00775', 'FeTS2022_00523', 'FeTS2022_00488', 'FeTS2022_00518', 'FeTS2022_00000', 'FeTS2022_00020', 'FeTS2022_01646', 'FeTS2022_01638', 'FeTS2022_00630', 'FeTS2022_01590', 'FeTS2022_01613', 'FeTS2022_01571', 'FeTS2022_00519', 'FeTS2022_01617', 'FeTS2022_01623', 'FeTS2022_00691', 'FeTS2022_01027', 'FeTS2022_00704', 'FeTS2022_00098', 'FeTS2022_01558', 'FeTS2022_00715', 'FeTS2022_00757', 'FeTS2022_00084', 'FeTS2022_00692', 'FeTS2022_00078', 'FeTS2022_00747', 'FeTS2022_01607', 'FeTS2022_00751', 'FeTS2022_00011', 'FeTS2022_00610', 'FeTS2022_00694', 'FeTS2022_00026', 'FeTS2022_00658', 'FeTS2022_01544', 'FeTS2022_01583', 'FeTS2022_00680', 'FeTS2022_01028', 'FeTS2022_01636', 'FeTS2022_00545', 'FeTS2022_00072', 'FeTS2022_00016', 'FeTS2022_01548', 'FeTS2022_00624', 'FeTS2022_00676', 'FeTS2022_00533', 'FeTS2022_01574', 'FeTS2022_01582', 'FeTS2022_00085', 'FeTS2022_00613', 'FeTS2022_01593', 'FeTS2022_00730', 'FeTS2022_01585', 'FeTS2022_00524', 'FeTS2022_00081', 'FeTS2022_00472', 'FeTS2022_00478', 'FeTS2022_00469', 'FeTS2022_00682', 'FeTS2022_00733', 'FeTS2022_00723', 'FeTS2022_00099', 'FeTS2022_00744', 'FeTS2022_00048', 'FeTS2022_00480', 'FeTS2022_00650', 'FeTS2022_00601', 'FeTS2022_00542', 'FeTS2022_00667', 'FeTS2022_00505', 'FeTS2022_01539', 'FeTS2022_00764', 'FeTS2022_00506', 'FeTS2022_01649', 'FeTS2022_00032', 'FeTS2022_00021', 'FeTS2022_00685', 'FeTS2022_00611', 'FeTS2022_00511', 'FeTS2022_01584', 'FeTS2022_01635', 'FeTS2022_00607', 'FeTS2022_00071', 'FeTS2022_00687', 'FeTS2022_00767', 'FeTS2022_00537', 'FeTS2022_01630', 'FeTS2022_00740', 'FeTS2022_00525', 'FeTS2022_00725', 'FeTS2022_00502', 'FeTS2022_01562', 'FeTS2022_01577', 'FeTS2022_01576', 'FeTS2022_01595', 'FeTS2022_00654', 'FeTS2022_00090', 'FeTS2022_01645', 'FeTS2022_01564', 'FeTS2022_01567', 'FeTS2022_00703', 'FeTS2022_00043', 'FeTS2022_00003', 'FeTS2022_00495', 'FeTS2022_00017', 'FeTS2022_00491', 'FeTS2022_00054', 'FeTS2022_00510', 'FeTS2022_00618', 'FeTS2022_00064', 'FeTS2022_00024', 'FeTS2022_00709', 'FeTS2022_01653', 'FeTS2022_01579', 'FeTS2022_01572', 'FeTS2022_01156', 'FeTS2022_00707', 'FeTS2022_01540', 'FeTS2022_00056', 'FeTS2022_00620', 'FeTS2022_00470', 'FeTS2022_00499', 'FeTS2022_00640', 'FeTS2022_00549', 'FeTS2022_01601', 'FeTS2022_00608', 'FeTS2022_00727', 'FeTS2022_00773', 'FeTS2022_00504', 'FeTS2022_01604', 'FeTS2022_01158', 'FeTS2022_00051', 'FeTS2022_00768', 'FeTS2022_01161', 'FeTS2022_00765', 'FeTS2022_00068', 'FeTS2022_00551', 'FeTS2022_01605', 'FeTS2022_00674', 'FeTS2022_01157', 'FeTS2022_01631', 'FeTS2022_00022', 'FeTS2022_00777', 'FeTS2022_01609', 'FeTS2022_01633', 'FeTS2022_01652', 'FeTS2022_00759', 'FeTS2022_01655', 'FeTS2022_01639', 'FeTS2022_01563', 'FeTS2022_00661', 'FeTS2022_00087', 'FeTS2022_00030', 'FeTS2022_00556', 'FeTS2022_01597', 'FeTS2022_00724', 'FeTS2022_00096', 'FeTS2022_00049', 'FeTS2022_00683', 'FeTS2022_00059', 'FeTS2022_01596', 'FeTS2022_00498', 'FeTS2022_00543', 'FeTS2022_01641', 'FeTS2022_01542', 'FeTS2022_00062', 'FeTS2022_00005', 'FeTS2022_00646', 'FeTS2022_00088', 'FeTS2022_00656', 'FeTS2022_01589', 'FeTS2022_01160', 'FeTS2022_01547', 'FeTS2022_01606', 'FeTS2022_00631', 'FeTS2022_00756', 'FeTS2022_00619', 'FeTS2022_00698', 'FeTS2022_01541', 'FeTS2022_00539', 'FeTS2022_00053', 'FeTS2022_01618', 'FeTS2022_00693', 'FeTS2022_00616', 'FeTS2022_01642', 'FeTS2022_01632', 'FeTS2022_00718', 'FeTS2022_00006', 'FeTS2022_00466', 'FeTS2022_01565', 'FeTS2022_01621', 'FeTS2022_00697', 'FeTS2022_00689', 'FeTS2022_00554', 'FeTS2022_00638', 'FeTS2022_00517', 'FeTS2022_00019', 'FeTS2022_01650', 'FeTS2022_01602', 'FeTS2022_01570', 'FeTS2022_00655', 'FeTS2022_00552', 'FeTS2022_00706', 'FeTS2022_01654', 'FeTS2022_00481', 'FeTS2022_00604', 'FeTS2022_00612', 'FeTS2022_00774', 'FeTS2022_00625', 'FeTS2022_00070', 'FeTS2022_00649', 'FeTS2022_00036', 'FeTS2022_01546', 'FeTS2022_00559', 'FeTS2022_00018', 'FeTS2022_00507', 'FeTS2022_00760', 'FeTS2022_01568', 'FeTS2022_00094', 'FeTS2022_00526', 'FeTS2022_01575', 'FeTS2022_00512', 'FeTS2022_00033', 'FeTS2022_01648', 'FeTS2022_00052', 'FeTS2022_01625', 'FeTS2022_01573', 'FeTS2022_00623', 'FeTS2022_01153', 'FeTS2022_00532', 'FeTS2022_00516', 'FeTS2022_00679', 'FeTS2022_00468', 'FeTS2022_00494', 'FeTS2022_00483', 'FeTS2022_01552', 'FeTS2022_00606', 'FeTS2022_00742', 'FeTS2022_00677', 'FeTS2022_00652', 'FeTS2022_00074', 'FeTS2022_00513', 'FeTS2022_01581', 'FeTS2022_00663', 'FeTS2022_00734', 'FeTS2022_01619', 'FeTS2022_00668', 'FeTS2022_00558', 'FeTS2022_00002', 'FeTS2022_01598', 'FeTS2022_00477', 'FeTS2022_01634', 'FeTS2022_00501', 'FeTS2022_01155', 'FeTS2022_00077', 'FeTS2022_01578', 'FeTS2022_01569', 'FeTS2022_01603', 'FeTS2022_00538', 'FeTS2022_00714', 'FeTS2022_00031', 'FeTS2022_01627', 'FeTS2022_01553', 'FeTS2022_00548', 'FeTS2022_00739', 'FeTS2022_00103', 'FeTS2022_00528', 'FeTS2022_01608', 'FeTS2022_00095', 'FeTS2022_00060', 'FeTS2022_01554', 'FeTS2022_00657', 'FeTS2022_01587', 'FeTS2022_00605', 'FeTS2022_00686', 'FeTS2022_00012']), (19, ['FeTS2022_01166', 'FeTS2022_01163', 'FeTS2022_01165', 'FeTS2022_01164']), (20, ['FeTS2022_00444', 'FeTS2022_01014', 'FeTS2022_00442', 'FeTS2022_01025', 'FeTS2022_01024', 'FeTS2022_00101', 'FeTS2022_00453', 'FeTS2022_01013', 'FeTS2022_01011', 'FeTS2022_00459', 'FeTS2022_00457', 'FeTS2022_01016', 'FeTS2022_00448', 'FeTS2022_01023', 'FeTS2022_01017', 'FeTS2022_00443', 'FeTS2022_00455', 'FeTS2022_00127', 'FeTS2022_01012', 'FeTS2022_01018', 'FeTS2022_01022', 'FeTS2022_00451', 'FeTS2022_00445', 'FeTS2022_00452', 'FeTS2022_00454', 'FeTS2022_01019', 'FeTS2022_01021', 'FeTS2022_01020', 'FeTS2022_01026', 'FeTS2022_00456', 'FeTS2022_00446', 'FeTS2022_00449', 'FeTS2022_01015']), (21, ['FeTS2022_00802', 'FeTS2022_00788', 'FeTS2022_00795', 'FeTS2022_00820', 'FeTS2022_00782', 'FeTS2022_00800', 'FeTS2022_00830', 'FeTS2022_00824', 'FeTS2022_00805', 'FeTS2022_00796', 'FeTS2022_00823', 'FeTS2022_00828', 'FeTS2022_00811', 'FeTS2022_00789', 'FeTS2022_00801', 'FeTS2022_00780', 'FeTS2022_00781', 'FeTS2022_00814', 'FeTS2022_00806', 'FeTS2022_00810', 'FeTS2022_00807', 'FeTS2022_00818', 'FeTS2022_00791', 'FeTS2022_00787', 'FeTS2022_00808', 'FeTS2022_00809', 'FeTS2022_00803', 'FeTS2022_00816', 'FeTS2022_00819', 'FeTS2022_00793', 'FeTS2022_00799', 'FeTS2022_00797', 'FeTS2022_00784', 'FeTS2022_00804', 'FeTS2022_00792']), (22, ['FeTS2022_01031', 'FeTS2022_01033', 'FeTS2022_01030', 'FeTS2022_00118', 'FeTS2022_01029', 'FeTS2022_00126', 'FeTS2022_01032']), (23, ['FeTS2022_01147', 'FeTS2022_01149', 'FeTS2022_01150', 'FeTS2022_01148', 'FeTS2022_01162'])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_map.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'flair': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01147/FeTS2022_01147_flair.nii.gz',\n",
       "  't1': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01147/FeTS2022_01147_t1.nii.gz',\n",
       "  't1ce': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01147/FeTS2022_01147_t1ce.nii.gz',\n",
       "  't2': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01147/FeTS2022_01147_t2.nii.gz',\n",
       "  'seg': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01147/FeTS2022_01147_seg.nii.gz'},\n",
       " {'flair': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01149/FeTS2022_01149_flair.nii.gz',\n",
       "  't1': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01149/FeTS2022_01149_t1.nii.gz',\n",
       "  't1ce': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01149/FeTS2022_01149_t1ce.nii.gz',\n",
       "  't2': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01149/FeTS2022_01149_t2.nii.gz',\n",
       "  'seg': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01149/FeTS2022_01149_seg.nii.gz'},\n",
       " {'flair': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01150/FeTS2022_01150_flair.nii.gz',\n",
       "  't1': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01150/FeTS2022_01150_t1.nii.gz',\n",
       "  't1ce': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01150/FeTS2022_01150_t1ce.nii.gz',\n",
       "  't2': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01150/FeTS2022_01150_t2.nii.gz',\n",
       "  'seg': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01150/FeTS2022_01150_seg.nii.gz'},\n",
       " {'flair': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01148/FeTS2022_01148_flair.nii.gz',\n",
       "  't1': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01148/FeTS2022_01148_t1.nii.gz',\n",
       "  't1ce': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01148/FeTS2022_01148_t1ce.nii.gz',\n",
       "  't2': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01148/FeTS2022_01148_t2.nii.gz',\n",
       "  'seg': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01148/FeTS2022_01148_seg.nii.gz'},\n",
       " {'flair': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01162/FeTS2022_01162_flair.nii.gz',\n",
       "  't1': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01162/FeTS2022_01162_t1.nii.gz',\n",
       "  't1ce': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01162/FeTS2022_01162_t1ce.nii.gz',\n",
       "  't2': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01162/FeTS2022_01162_t2.nii.gz',\n",
       "  'seg': '/home/locolinux2/datasets/MICCAI_FeTS2022_TrainingData/FeTS2022_01162/FeTS2022_01162_seg.nii.gz'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [04:37<00:00,  1.84it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:07<00:00,  1.88it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:24<00:00,  1.88it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:11<00:00,  1.89it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:17<00:00,  1.89it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06<00:00,  1.80it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.81it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:08<00:00,  1.72it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:06<00:00,  1.65it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:19<00:00,  1.78it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.73it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.59it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:28<00:00,  1.04it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:06<00:00,  1.49it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 382/382 [08:59<00:00,  1.41s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:27<00:00,  1.19it/s]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:53<00:00,  1.52s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.37s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.  Build per-client datasets & dataloaders\n",
    "# -----------------------------------------------------------\n",
    "train_datasets = {}     # {client_id: monai CacheDataset}\n",
    "for cid, subj_list in partition_map.items():\n",
    "    records = build_records(subj_list)\n",
    "    train_datasets[cid] = CacheDataset(data=records, transform=train_tf, cache_rate=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7.  Build test dataset & dataloader\n",
    "# -----------------------------------------------------------\n",
    "val_records  = build_val_records(VAL_DIR)\n",
    "test_dataset  = CacheDataset(data=val_records, transform=val_tf, cache_rate=1.0)\n",
    "# test_loader   = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DrrjBXZg4rEN"
   },
   "outputs": [],
   "source": [
    "# class CustomTensorDataset(Dataset):\n",
    "#     \"\"\"TensorDataset with support of transforms.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, tensors, transform=None):\n",
    "#         self.tensors = tensors\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         x = self.tensors[0][index]\n",
    "\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "\n",
    "#         y = self.tensors[1][index]\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.tensors[0].shape[0]\n",
    "\n",
    "def test_inference(model, test_dataset):\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    testloader = DataLoader(test_dataset, batch_size=200, shuffle=False)\n",
    "\n",
    "    for _, (images, labels) in enumerate(testloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        loss += batch_loss.item()\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WTUtuKlu4Ddo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 23 clients\n"
     ]
    }
   ],
   "source": [
    "# N = 10 #srch\n",
    "N = list(train_datasets.keys())[-1]\n",
    "print(f\"We got {N} clients\")\n",
    "local_bs = 512\n",
    "lr = 0.01\n",
    "local_ep = 5\n",
    "EPOCHS = 5\n",
    "\n",
    "# noise_rates = np.linspace(0, 1, N, endpoint=False)\n",
    "# split_dset = mnist_iid(trainset, N)\n",
    "# user_groups = {i: 0 for i in range(1, N+1)}\n",
    "# noise_idx = {i: 0 for i in range(1, N+1)}\n",
    "# train_datasets = {i: 0 for i in range(1, N+1)}\n",
    "# for n in range(N):\n",
    "#     user_groups[n+1] = np.array(list(split_dset[n]), dtype=np.int)\n",
    "#     user_train_x, user_train_y = x_train[user_groups[n+1]], y_train[user_groups[n+1]]\n",
    "#     user_noisy_y, noise_idx[n+1] = noisify_MNIST(noise_rates[n], 'symmetric', user_train_x, user_train_y)\n",
    "    \n",
    "#     train_datasets[n+1] = CustomTensorDataset((user_train_x, user_noisy_y), transform_train)\n",
    "\n",
    "def fixfuckingbn(subset_weights, global_model_state_dict):\n",
    "    for pair_1, pair_2 in zip(subset_weights.items(), global_model_state_dict.items()):\n",
    "        if ('running' in pair_1[0]) or ('batches' in pair_1[0]):\n",
    "            subset_weights[pair_1[0]] = global_model_state_dict[pair_1[0]]\n",
    "    \n",
    "    return subset_weights\n",
    "\n",
    "global_model = ResNet9().to(device)\n",
    "global_model.to(device)\n",
    "global_model.train()\n",
    "\n",
    "global_weights = global_model.state_dict()\n",
    "powerset = list(powersettool(range(1, N+1)))\n",
    "submodel_dict = {}  \n",
    "submodel_dict[()] = copy.deepcopy(global_model)\n",
    "accuracy_dict = {}\n",
    "shapley_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <monai.data.dataset.CacheDataset at 0x7fc0d9586f70>,\n",
       " 2: <monai.data.dataset.CacheDataset at 0x7fc2c40a9eb0>,\n",
       " 3: <monai.data.dataset.CacheDataset at 0x7fc0cc62b070>,\n",
       " 4: <monai.data.dataset.CacheDataset at 0x7fc0daabae20>,\n",
       " 5: <monai.data.dataset.CacheDataset at 0x7fc0d9470700>,\n",
       " 6: <monai.data.dataset.CacheDataset at 0x7fc0d94a7ee0>,\n",
       " 7: <monai.data.dataset.CacheDataset at 0x7fc0d887da30>,\n",
       " 8: <monai.data.dataset.CacheDataset at 0x7fc0cc17e0d0>,\n",
       " 9: <monai.data.dataset.CacheDataset at 0x7fc0cd58fe20>,\n",
       " 10: <monai.data.dataset.CacheDataset at 0x7fc0cd5aae80>,\n",
       " 11: <monai.data.dataset.CacheDataset at 0x7fc0d94e1be0>,\n",
       " 12: <monai.data.dataset.CacheDataset at 0x7fc0d9586160>,\n",
       " 13: <monai.data.dataset.CacheDataset at 0x7fc0d94c7490>,\n",
       " 14: <monai.data.dataset.CacheDataset at 0x7fc0d94dabe0>,\n",
       " 15: <monai.data.dataset.CacheDataset at 0x7fc0d963ae20>,\n",
       " 16: <monai.data.dataset.CacheDataset at 0x7fc0d93d0c40>,\n",
       " 17: <monai.data.dataset.CacheDataset at 0x7fc0d94c77f0>,\n",
       " 18: <monai.data.dataset.CacheDataset at 0x7fc0f029a7c0>,\n",
       " 19: <monai.data.dataset.CacheDataset at 0x7fc0cc62bee0>,\n",
       " 20: <monai.data.dataset.CacheDataset at 0x7fc0d95a47f0>,\n",
       " 21: <monai.data.dataset.CacheDataset at 0x7fc0d95a4520>,\n",
       " 22: <monai.data.dataset.CacheDataset at 0x7fc0d95b1a90>,\n",
       " 23: <monai.data.dataset.CacheDataset at 0x7fc0da7dd160>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet9, self).__init__()\n",
    "        self.prep = self.convbnrelu(channels=3, filters=64)\n",
    "        self.layer1 = self.convbnrelu(64, 128)\n",
    "        self.layer_pool = nn.MaxPool2d(2, 2, 0, 1, ceil_mode=False)\n",
    "        self.layer1r1 = self.convbnrelu(128, 128)\n",
    "        self.layer1r2 = self.convbnrelu(128, 128)\n",
    "        self.layer2 = self.convbnrelu(128, 256)\n",
    "        self.layer3 = self.convbnrelu(256, 512)\n",
    "        self.layer3r1 = self.convbnrelu(512, 512)\n",
    "        self.layer3r2 = self.convbnrelu(512, 512)\n",
    "        self.out_pool = nn.MaxPool2d(kernel_size=4, stride=4, ceil_mode=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(in_features=512, out_features=10, bias=False)\n",
    "\n",
    "    def convbnrelu(self, channels, filters):\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(channels, filters, (3, 3),\n",
    "                                (1, 1), (1, 1), bias=False))\n",
    "        layers.append(nn.BatchNorm2d(filters, track_running_stats=False))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer_pool(self.layer1(x))\n",
    "        r1 = self.layer1r2(self.layer1r1(x)) \n",
    "        x = x + r1\n",
    "        x = self.layer_pool(self.layer2(x))\n",
    "        x = self.layer_pool(self.layer3(x))\n",
    "        r3 = self.layer3r2(self.layer3r1(x))\n",
    "        x = x + r3\n",
    "        out = self.out_pool(x)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        out = out * 0.125\n",
    "\n",
    "        return out\n",
    "        \n",
    "class LocalUpdate(object):\n",
    "\n",
    "    def __init__(self, lr, local_ep, trainloader):\n",
    "        self.lr = lr\n",
    "        self.local_ep = local_ep\n",
    "        self.trainloader = trainloader\n",
    "\n",
    "    def update_weights(self, model):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        for iter in range(self.local_ep):\n",
    "            batch_loss = []\n",
    "            for batch_idx, (images, labels) in enumerate(self.trainloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                model.zero_grad()   \n",
    "                log_probs = model(images)\n",
    "                loss = criterion(log_probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "        return model.state_dict(), sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvXdFSu24Iq6",
    "outputId": "76c751e1-1bbf-49a6-9803-df0517c62df5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                 | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for subset in range(1, N+1):\n",
    "    submodel_dict[(subset,)] = copy.deepcopy(global_model)\n",
    "    submodel_dict[(subset,)].to(device)\n",
    "    submodel_dict[(subset,)].train() \n",
    " \n",
    "train_loss, train_accuracy = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "print_every = 1\n",
    "\n",
    "idxs_users = np.arange(1, N+1)\n",
    "# total_data = sum(len(user_groups[i]) for i in range(1, N+1))\n",
    "# fraction = [len(user_groups[i])/total_data for i in range(1, N+1)]\n",
    "\n",
    "# ── collect dataset sizes ──────────────────────────────────────────────────\n",
    "# MONAI's CacheDataset inherits __len__, so `len(ds)` is cheap:\n",
    "sizes = {k: len(ds) for k, ds in train_datasets.items()}\n",
    "\n",
    "# ── total samples across all clients ───────────────────────────────────────\n",
    "total_data = sum(sizes.values())\n",
    "\n",
    "# ── FedAvg weight (a.k.a. fraction) for each client ────────────────────────\n",
    "# Keep the list in key order 1…N so it lines up with your loops later.\n",
    "fraction = [sizes[i] / total_data for i in range(1, N + 1)]\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')\n",
    "    global_model.train()\n",
    "    for idx in idxs_users:\n",
    "        trainloader = DataLoader(train_datasets[idx], batch_size=local_bs, shuffle=True)\n",
    "        local_model = LocalUpdate(lr, local_ep, trainloader)\n",
    "        w, loss = local_model.update_weights(model=copy.deepcopy(global_model))\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "    global_weights = average_weights(local_weights, fraction) \n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    gradients = calculate_gradients(local_weights, global_model.state_dict()) \n",
    "    for i in range(1, N+1):\n",
    "        subset_weights = update_weights_from_gradients(gradients[i-1], submodel_dict[(i,)].state_dict()) \n",
    "        subset_weights = fixfuckingbn(subset_weights, global_model.state_dict())\n",
    "        submodel_dict[(i,)].load_state_dict(subset_weights)\n",
    "\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    global_model.eval()\n",
    "\n",
    "    if (epoch+1) % print_every == 0:\n",
    "        print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        # print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "\n",
    "test_acc, test_loss = test_inference(global_model, test_dataset)\n",
    "print(f' \\n Results after {EPOCHS} global rounds of training:')\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "accuracy_dict[powerset[-1]] = test_acc\n",
    "\n",
    "# ADJUSTED-OR APPROX\n",
    "for subset in powerset[:-1]: \n",
    "    if len(subset) > 1:\n",
    "        # calculate the average of the subset of weights from list of all the weights\n",
    "        subset_weights = average_weights([submodel_dict[(i,)].state_dict() for i in subset], [fraction[i-1] for i in subset]) \n",
    "        submodel = copy.deepcopy(submodel_dict[()])\n",
    "        submodel.load_state_dict(subset_weights)\n",
    "        \n",
    "        test_acc, test_loss = test_inference(submodel,test_dataset)\n",
    "        print(f' \\n Results after {EPOCHS} global rounds of training (for OR): ')\n",
    "        print(\"|---- Test Accuracy for {}: {:.2f}%\".format(subset, 100*test_acc))\n",
    "        accuracy_dict[subset] = test_acc\n",
    "    else: \n",
    "        test_acc, test_loss = test_inference(submodel_dict[subset], test_dataset)\n",
    "        accuracy_dict[subset] = test_acc\n",
    "\n",
    "trainTime = time.time() - start_time\n",
    "start_time = time.time()\n",
    "shapley_dict = shapley(accuracy_dict, N)\n",
    "shapTime = time.time() - start_time\n",
    "start_time = time.time()\n",
    "lc_dict = least_core(accuracy_dict, N)\n",
    "LCTime = time.time() - start_time\n",
    "totalShapTime = trainTime + shapTime\n",
    "totalLCTime = trainTime + LCTime\n",
    "print(f'\\n ACCURACY: {accuracy_dict[powerset[-1]]}')\n",
    "print('\\n Total Time Shapley: {0:0.4f}'.format(totalShapTime))\n",
    "print('\\n Total Time LC: {0:0.4f}'.format(totalLCTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOBqzOdQRfIe"
   },
   "outputs": [],
   "source": [
    "def stats(vector):\n",
    "    n = len(vector)\n",
    "    egal = np.array([1/n for i in range(n)])\n",
    "    normalised = np.array(vector / vector.sum())\n",
    "    msg = f'Original vector: {vector}\\n'\n",
    "    msg += f'Normalised vector: {normalised}\\n'\n",
    "    msg += f'Max Dif: {normalised.max()-normalised.min()}\\n'\n",
    "    msg += f'Distance: {np.linalg.norm(normalised-egal)}\\n'\n",
    "\n",
    "    msg += f'Budget: {vector.sum()}\\n'\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWyxrrCUwOxO",
    "outputId": "50b2f298-6572-4de7-8942-4065a3e2b0c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [ 0.12156075  0.10917627  0.10981044  0.10419635  0.07705849  0.07902048\n",
      "  0.04776313  0.03351619 -0.03449246 -0.12100964]\n",
      "Normalised vector: [ 0.23084078  0.20732296  0.20852722  0.19786622  0.14633212  0.15005787\n",
      "  0.09070098  0.06364639 -0.0655003  -0.22979423]\n",
      "Max Dif: 0.4606350110622801\n",
      "Distance: 0.4384159898612196\n",
      "Budget: 0.5266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats(np.array(list(shapley_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZ3ZJVjFJA1c",
    "outputId": "86f4a6b1-a728-45ea-83d6-7d9913b59823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [0.100125 0.       0.091025 0.107525 0.101125 0.0763   0.0948   0.0561\n",
      " 0.       0.      ]\n",
      "Normalised vector: [0.159689   0.         0.14517544 0.17149123 0.16128389 0.12169059\n",
      " 0.15119617 0.08947368 0.         0.        ]\n",
      "Max Dif: 0.17149122807017544\n",
      "Distance: 0.21834065249685256\n",
      "Budget: 0.627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats(np.array([i.value() for i in lc_dict.variables()])[1:])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMNKnjfLFi/+UJW/ZI4jUCD",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ISO CIFAR10 OR FINAL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
