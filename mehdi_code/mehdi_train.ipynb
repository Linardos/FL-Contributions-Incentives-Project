{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8937d7ff-6be2-4d2b-b03e-1be0d161ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/nnunet/preprocessed /mnt/d/nnunet/results /mnt/d/nnunet/raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"nnUNet_raw\"] = \"/mnt/d/nnunet/raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/mnt/d/nnunet/preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/mnt/d/nnunet/results\"\n",
    "\n",
    "from nnunetv2.paths import nnUNet_preprocessed, nnUNet_results, nnUNet_raw\n",
    "\n",
    "print(nnUNet_preprocessed, nnUNet_results, nnUNet_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc330824-94fb-4b31-8f93-25475ce53e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from nnunet_api import NnUnetApi\n",
    "from tools.data_reformat import data_prepare\n",
    "from tools.json_pickle_stuff import copy_plans_json\n",
    "\n",
    "# =================================================================================\n",
    "# 1. Configuration\n",
    "# =================================================================================\n",
    "# --- Define the IDs and paths for your datasets and models ---\n",
    "\n",
    "# ABS path to the raw data directory: each subject has its own folder with BraTS namind convention\n",
    "RAW_DATA_PATH = \"/mnt/d/Datasets/mehdi_code_test/sample_data\" #\"PATH_TO_SAMPLE_RAW_DATA\"\n",
    "\n",
    "# The Dataset ID of the model you want to use for pre-training.\n",
    "# This model's architecture and plans will be transferred to your new dataset.\n",
    "PRETRAINED_DATASET_ID = 770\n",
    "\n",
    "# The Dataset ID of your new dataset that you want to fine-tune on.\n",
    "# Make sure you have already converted this dataset to the nnU-Net format.\n",
    "FINETUNE_DATASET_ID = 666\n",
    "\n",
    "# An identifier for the new plans that will be created for your fine-tuning dataset.\n",
    "# It's good practice to give it a descriptive name.\n",
    "FINETUNE_PLANS_ID = 'nnUNetPlans_finetune_from_brats'\n",
    "\n",
    "# The full path to the pre-trained model's checkpoint file.\n",
    "# This file contains the weights that will be used to initialize your new model.\n",
    "PRETRAINED_CHECKPOINT_PATH = os.path.join(nnUNet_results, \"Dataset770_BraTSGLIPreCropRegion/nnUNetTrainer__nnUNetResEncUNetPlans__3d_fullres/fold_0/checkpoint_final.pth\")\n",
    "\n",
    "# The GPU device to use for training.\n",
    "# DEVICE = torch.device('cuda')\n",
    "\n",
    "# Fold number you want to train (on the fine tunning dataset)\n",
    "FOLD = 0\n",
    "\n",
    "# NUMBER of epochs to train the model\n",
    "N_EPOCHS = 3\n",
    "\n",
    "# Initial Learning Rate for model training\n",
    "INIT_LR = 1e-3\n",
    "\n",
    "# ABS Path to the folder where testing data is located\n",
    "INPUT_FOLDER_INFER = \"/mnt/d/Datasets/mehdi_code_test/sample_test_decathlon\" #'PATH_TO_TESTING_DATA'\n",
    "\n",
    "# ABS Path to the folder where the results of inference will be saved\n",
    "OUTPUT_FOLDER_INFER_FINETUNE = './test_ftune' #'PATH_TO_SAVE_RESULTS_FINETUNE'\n",
    "OUTPUT_FOLDER_INFER_PRETRAINED = './test_pretrain' #'PATH_TO_SAVE_RESULTS_PRETRAINED'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dccfdb0-c049-42f8-9300-ba88362a909b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0: Running Data Preparation script...\n",
      "--------\n",
      "data reformat in process for case 1 out of 10 ...\n",
      "data reformat in process for case 2 out of 10 ...\n",
      "data reformat in process for case 3 out of 10 ...\n",
      "data reformat in process for case 4 out of 10 ...\n",
      "data reformat in process for case 5 out of 10 ...\n",
      "data reformat in process for case 6 out of 10 ...\n",
      "data reformat in process for case 7 out of 10 ...\n",
      "data reformat in process for case 8 out of 10 ...\n",
      "data reformat in process for case 9 out of 10 ...\n",
      "data reformat in process for case 10 out of 10 ...\n",
      "--------\n",
      "All files were reformated, ready for segmentation!\n"
     ]
    }
   ],
   "source": [
    "# ## --- Step 00: Preparing the raw dataset into Decathlon format\n",
    "print(\"\\nStep 0: Running Data Preparation script...\")\n",
    "DST_DATA_NAME = \"Dataset\"+str(FINETUNE_DATASET_ID)+\"_finetune_Decathlon\"\n",
    "data_prepare(RAW_DATA_PATH, os.path.join(nnUNet_raw, DST_DATA_NAME))\n",
    "n_case=len(os.listdir(os.path.join(nnUNet_raw, DST_DATA_NAME,\"labelsTr\")))\n",
    "copy_plans_json(\"./dataset.json\", os.path.join(nnUNet_raw, DST_DATA_NAME), n_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094a821d-219c-419e-a023-8dee260f33d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting fingerprint for Dataset 666...\n",
      "Dataset666_finetune_Decathlon\n",
      "-> Fingerprint extracted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =================================================================================\n",
    "# 2. Initialize the API\n",
    "# =================================================================================\n",
    "api = NnUnetApi()\n",
    "## --- Step 1: Extract the Fingerprint for Your New Dataset ---\n",
    "## This step analyzes the properties of your new dataset (image sizes, spacings, etc.)\n",
    "## and creates a \"fingerprint\" file. This is a prerequisite for any planning.\n",
    "## This wraps: nnUNetv2_extract_fingerprint CLI\n",
    "print(f\"Step 1: Extracting fingerprint for Dataset {FINETUNE_DATASET_ID}...\")\n",
    "api.extract_fingerprint(\n",
    "    finetune_dataset_id=FINETUNE_DATASET_ID\n",
    ")\n",
    "print(\"-> Fingerprint extracted.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67193b95-789c-4dfa-bb2f-c323ce6f1af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Applying plans from Dataset 770 to Dataset 666...\n",
      "-> Plans applied. New plans identifier is 'nnUNetPlans_finetune_from_brats'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Load and Apply the Pre-trained Model's Plans ---\n",
    "# This is the key step for aligning architectures. It takes the plans\n",
    "# (network topology, patch size, normalization, etc.) from the pre-trained\n",
    "# model and applies them to your new dataset's fingerprint, creating a new\n",
    "# plan file specifically for fine-tuning.\n",
    "# This wraps: nnUNetv2_move_plans_between_datasets CLI\n",
    "print(f\"Step 2: Applying plans from Dataset {PRETRAINED_DATASET_ID} to Dataset {FINETUNE_DATASET_ID}...\")\n",
    "api.apply_pretrained_plans(\n",
    "    pretrained_dataset_id=PRETRAINED_DATASET_ID,\n",
    "    finetune_dataset_id=FINETUNE_DATASET_ID,\n",
    "    finetune_plans_identifier=FINETUNE_PLANS_ID\n",
    ")\n",
    "print(f\"-> Plans applied. New plans identifier is '{FINETUNE_PLANS_ID}'.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd182c4-e876-4ee8-a691-b706e623b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Preprocessing Dataset 666 with the new plans...\n",
      "Preprocessing dataset Dataset666_finetune_Decathlon\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:44<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Preprocessing complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Preprocess Your New Dataset ---\n",
    "# Now that your fine-tuning dataset has a valid (and aligned) plan file,\n",
    "# you can run the standard preprocessing pipeline on it. This will resample,\n",
    "# crop, and normalize your images according to the new plan.\n",
    "# This wraps: nnUNetv2_preprocess CLI\n",
    "print(f\"Step 3: Preprocessing Dataset {FINETUNE_DATASET_ID} with the new plans...\")\n",
    "api.preprocess_dataset(\n",
    "    dataset_id=FINETUNE_DATASET_ID,\n",
    "    plans_identifier=FINETUNE_PLANS_ID\n",
    ")\n",
    "print(\"-> Preprocessing complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4f8b80-845d-4c2d-8592-cbacf3c1960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Starting fine-tuning on Dataset 666...\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-21 10:51:09.433731: Using torch.compile...\n",
      "################### Loading pretrained weights from file  /mnt/d/nnunet/results/Dataset770_BraTSGLIPreCropRegion/nnUNetTrainer__nnUNetResEncUNetPlans__3d_fullres/fold_0/checkpoint_final.pth ###################\n",
      "Below is the list of overlapping blocks in pretrained model and nnUNet architecture:\n",
      "encoder.stem.convs.0.conv.weight shape torch.Size([32, 4, 3, 3, 3])\n",
      "encoder.stem.convs.0.conv.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.norm.weight shape torch.Size([32])\n",
      "encoder.stem.convs.0.norm.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.0.weight shape torch.Size([32, 4, 3, 3, 3])\n",
      "encoder.stem.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.conv.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.conv.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.bias shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.weight shape torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.bias shape torch.Size([32])\n",
      "encoder.stages.1.blocks.0.conv1.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.conv.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.0.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.conv.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "encoder.stages.2.blocks.0.conv1.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.conv.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.0.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.conv.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "encoder.stages.3.blocks.0.conv1.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.conv.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.0.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.conv.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "encoder.stages.4.blocks.0.conv1.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.conv.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.0.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stem.convs.0.conv.weight shape torch.Size([32, 4, 3, 3, 3])\n",
      "decoder.encoder.stem.convs.0.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.weight shape torch.Size([32, 4, 3, 3, 3])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.conv.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.0.weight shape torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.conv.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.0.weight shape torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.conv.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.0.weight shape torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.conv.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.0.weight shape torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.conv.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.weight shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])\n",
      "decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.conv.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.weight shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])\n",
      "decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.conv.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.weight shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])\n",
      "decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.conv.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.weight shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])\n",
      "decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])\n",
      "decoder.stages.4.convs.0.conv.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.weight shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])\n",
      "decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])\n",
      "decoder.transpconvs.0.weight shape torch.Size([320, 320, 2, 2, 2])\n",
      "decoder.transpconvs.0.bias shape torch.Size([320])\n",
      "decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])\n",
      "decoder.transpconvs.1.bias shape torch.Size([256])\n",
      "decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])\n",
      "decoder.transpconvs.2.bias shape torch.Size([128])\n",
      "decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])\n",
      "decoder.transpconvs.3.bias shape torch.Size([64])\n",
      "decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])\n",
      "decoder.transpconvs.4.bias shape torch.Size([32])\n",
      "################### Done ###################\n",
      "2025-10-21 10:51:29.271998: do_dummy_2d_data_aug: False\n",
      "2025-10-21 10:51:29.285877: Creating new 5-fold cross-validation split...\n",
      "2025-10-21 10:51:29.321973: Desired fold for training: 0\n",
      "2025-10-21 10:51:29.328861: This split has 8 training and 2 validation cases.\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/locolinux2/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_finetune_from_brats_nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [140.0, 171.0, 137.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset666_finetune_Decathlon', 'plans_name': 'nnUNetPlans_finetune_from_brats', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 171, 137], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ResEncUNetPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 100487.5078125, 'mean': 871.8157348632812, 'median': 407.0, 'min': 0.10992202162742615, 'percentile_00_5': 55.0, 'percentile_99_5': 5821.573669433674, 'std': 2023.704345703125}, '1': {'max': 1905559.25, 'mean': 1696.11767578125, 'median': 552.0, 'min': 0.0, 'percentile_00_5': 47.0, 'percentile_99_5': 8323.0, 'std': 18698.162109375}, '2': {'max': 4438107.0, 'mean': 2139.482666015625, 'median': 738.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 10387.0, 'std': 45062.19140625}, '3': {'max': 527453.1875, 'mean': 995.2467041015625, 'median': 512.4065246582031, 'min': 0.0, 'percentile_00_5': 108.0, 'percentile_99_5': 11909.0, 'std': 4625.27392578125}}} \n",
      "\n",
      "2025-10-21 10:51:38.966577: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-21 10:51:39.006714: \n",
      "2025-10-21 10:51:39.014574: Epoch 0\n",
      "2025-10-21 10:51:39.044991: Current learning rate: 0.001\n"
     ]
    },
    {
     "ename": "InductorError",
     "evalue": "RuntimeError: Failed to find C compiler. Please specify via CC environment variable or set triton.knobs.build.impl.\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInductorError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Step 4: Run the Fine-Tuning Training ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Finally, you can start the training process. This function works just like the\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# standard `train` method but includes the `pretrained_weights` argument.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# nnU-Net will load the weights from the specified checkpoint file before starting\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the training, effectively fine-tuning the model on your new data.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# This wraps: nnUNetv2_train -pretrained_weights CLI\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep 4: Starting fine-tuning on Dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINETUNE_DATASET_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetune_dataset_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_DATASET_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3d_fullres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFOLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_checkpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRETRAINED_CHECKPOINT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplans_identifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_PLANS_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINIT_LR\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFine-tuning process has been started!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/FL-Contributions-Incentives-Project/mehdi_code/nnunet_api.py:122\u001b[0m, in \u001b[0;36mNnUnetApi.finetune\u001b[0;34m(self, finetune_dataset_id, configuration, fold, pretrained_checkpoint_path, plans_identifier, trainer_class_name, num_epochs, initial_lr, device)\u001b[0m\n\u001b[1;32m    119\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43mnnunet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1371\u001b[0m, in \u001b[0;36mnnUNetTrainer.run_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations_per_epoch):\n\u001b[0;32m-> 1371\u001b[0m     train_outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_train_epoch_end(train_outputs)\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:989\u001b[0m, in \u001b[0;36mnnUNetTrainer.train_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# Autocast can be annoying\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# If the device_type is 'cpu' then it's slow as heck and needs to be disabled.\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# If the device_type is 'mps' then it will complain that mps is not implemented, even if enabled=False is set. Whyyyyyyy. (this is why we don't make use of enabled=False)\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# So autocast will only be active if we have a cuda device.\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dummy_context():\n\u001b[0;32m--> 989\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# del data\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(output, target)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:375\u001b[0m, in \u001b[0;36mOptimizedModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39m_has_any_global_hook():\n\u001b[1;32m    366\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `torch.compile(module)` when there are global hooks on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodules (e.g., from `register_module_forward_hook`); this will\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    374\u001b[0m     )\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:749\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__cause__\u001b[39;00m  \u001b[38;5;66;03m# User compiler error\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ShortenTraceback \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# Failures in the backend likely don't have useful\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# data in the TorchDynamo frames, so we strip them out.\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mremove_dynamo_frames() \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# see TORCHDYNAMO_VERBOSE=1\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:923\u001b[0m, in \u001b[0;36m_compile_fx_inner\u001b[0;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InductorError(e, currentframe())\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[1;32m    924\u001b[0m         e\u001b[38;5;241m.\u001b[39m__traceback__\n\u001b[1;32m    925\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    927\u001b[0m     TritonBundler\u001b[38;5;241m.\u001b[39mend_compile()\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:907\u001b[0m, in \u001b[0;36m_compile_fx_inner\u001b[0;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m TritonBundler\u001b[38;5;241m.\u001b[39mbegin_compile()\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 907\u001b[0m     mb_compiled_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     mb_compiled_graph\u001b[38;5;241m.\u001b[39m_time_taken_ns \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1578\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheme, _OutOfProcessFxCompile), (\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync is only valid with an out-of-process compile mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     scheme \u001b[38;5;241m=\u001b[39m _AsyncFxCompile(scheme)\n\u001b[0;32m-> 1578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1456\u001b[0m, in \u001b[0;36m_InProcessFxCompile.codegen_and_compile\u001b[0;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         compiled_fn \u001b[38;5;241m=\u001b[39m AotCodeCompiler\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1439\u001b[0m             graph,\n\u001b[1;32m   1440\u001b[0m             wrapper_code\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m             ],\n\u001b[1;32m   1454\u001b[0m         )\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1456\u001b[0m     compiled_module \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m compiled_module\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m   1458\u001b[0m     compiled_fn_runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   1459\u001b[0m         compiled_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/graph.py:2293\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledModule:\n\u001b[1;32m   2287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[1;32m   2288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphLowering.compile_to_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2289\u001b[0m         phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_gen\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2290\u001b[0m         log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2291\u001b[0m         dynamo_compile_column_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2292\u001b[0m     ):\n\u001b[0;32m-> 2293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/graph.py:2299\u001b[0m, in \u001b[0;36mGraphLowering._compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledModule:\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# If we're here, we don't have to worry about the kernel code, which is only\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     \u001b[38;5;66;03m# returned separately in AOTInductor mode.\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m     wrapper_code, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 2299\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2300\u001b[0m     )\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(wrapper_code, ValueWithLineMap):\n\u001b[1;32m   2303\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_to_module_lines(wrapper_code)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/graph.py:2238\u001b[0m, in \u001b[0;36mGraphLowering.codegen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2235\u001b[0m V\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mdraw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_gm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_code\u001b[38;5;241m.\u001b[39mpush_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 2238\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2240\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   2241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished codegen for all nodes. The list of kernel names available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2242\u001b[0m     V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mall_codegen_kernel_names,\n\u001b[1;32m   2243\u001b[0m )\n\u001b[1;32m   2245\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_code\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_inference)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/scheduler.py:4598\u001b[0m, in \u001b[0;36mScheduler.codegen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcodegen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduler.codegen\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   4595\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   4596\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codegen_partitions()\n\u001b[1;32m   4597\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_inductor\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgraph_partition\n\u001b[0;32m-> 4598\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codegen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4599\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/scheduler.py:4750\u001b[0m, in \u001b[0;36mScheduler._codegen\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m   4748\u001b[0m     backend\u001b[38;5;241m.\u001b[39mcodegen_combo_kernel(node)\n\u001b[1;32m   4749\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (FusedSchedulerNode, SchedulerNode)):\n\u001b[0;32m-> 4750\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, NopKernelSchedulerNode)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/codegen/cuda_combined_scheduling.py:107\u001b[0m, in \u001b[0;36mCUDACombinedScheduling.codegen_node\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcodegen_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: Union[FusedSchedulerNode, SchedulerNode]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_triton_scheduling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/codegen/simd.py:1371\u001b[0m, in \u001b[0;36mSIMDScheduling.codegen_node\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1368\u001b[0m node_schedule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_node_schedule(nodes, numel, rnumel)\n\u001b[1;32m   1369\u001b[0m schedule_log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchedule:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, node_schedule)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node_schedule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSIMDKernelFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoalesce_analysis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/codegen/simd.py:1424\u001b[0m, in \u001b[0;36mSIMDScheduling.codegen_node_schedule\u001b[0;34m(self, kernel_features)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_kernel_handler(kernel):\n\u001b[0;32m-> 1424\u001b[0m         src_code \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m     kernel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefine_kernel(src_code, node_schedule, kernel)\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39menabled:\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/codegen/triton.py:3677\u001b[0m, in \u001b[0;36mTritonKernel.codegen_kernel\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3662\u001b[0m \u001b[38;5;66;03m# Skip memory optimization for forward of the training loop where we expect\u001b[39;00m\n\u001b[1;32m   3663\u001b[0m \u001b[38;5;66;03m# every new node will increase the peak memory and our greedy approach would\u001b[39;00m\n\u001b[1;32m   3664\u001b[0m \u001b[38;5;66;03m# introduce a lot of unnecessary cpu copies.\u001b[39;00m\n\u001b[1;32m   3665\u001b[0m optimize_mem \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_inference \u001b[38;5;129;01mor\u001b[39;00m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_backward\n\u001b[1;32m   3667\u001b[0m inductor_meta \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3668\u001b[0m     \u001b[38;5;66;03m# Triton will not accept an OrderedSet for autotune_hints\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrid_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_grid_type()\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m   3670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_hints\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_hints),  \u001b[38;5;66;03m# noqa: set_linter\u001b[39;00m\n\u001b[1;32m   3671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(Placeholder\u001b[38;5;241m.\u001b[39mDESCRIPTIVE_NAME),\n\u001b[1;32m   3672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmutated_arg_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: mutated_args,\n\u001b[1;32m   3673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize_mem\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimize_mem,\n\u001b[1;32m   3674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_x_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_x_dim,\n\u001b[1;32m   3675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_load\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_load,\n\u001b[1;32m   3676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_reduction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_reduction,\n\u001b[0;32m-> 3677\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minductor_meta_common\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3678\u001b[0m }\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiling_scores:\n\u001b[1;32m   3680\u001b[0m     inductor_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiling_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiling_scores\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/_inductor/codegen/triton.py:3501\u001b[0m, in \u001b[0;36mTritonKernel.inductor_meta_common\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minductor_meta_common\u001b[39m():\n\u001b[1;32m   3500\u001b[0m     inductor_meta \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m-> 3501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_triton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriton_hash_with_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare_deterministic_algorithms_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled(),\n\u001b[1;32m   3503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_indirect_indexing\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39massert_indirect_indexing,\n\u001b[1;32m   3504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_local_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mautotune_local_cache,\n\u001b[1;32m   3505\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_pointwise\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mautotune_pointwise,\n\u001b[1;32m   3506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_remote_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mautotune_remote_cache,\n\u001b[1;32m   3507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_disable_caches\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mforce_disable_caches,\n\u001b[1;32m   3508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamic_scale_rblock\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mdynamic_scale_rblock,\n\u001b[1;32m   3509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_autotune\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_autotune,\n\u001b[1;32m   3510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_autotune_pointwise\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_autotune_pointwise,\n\u001b[1;32m   3511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_split_scan_rblock\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mmin_split_scan_rblock,\n\u001b[1;32m   3512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspill_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mspill_threshold,\n\u001b[1;32m   3513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_cubin\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mstore_cubin,\n\u001b[1;32m   3514\u001b[0m     }\n\u001b[1;32m   3515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3516\u001b[0m         inductor_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_hip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/utils/_triton.py:165\u001b[0m, in \u001b[0;36mtriton_hash_with_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtriton_hash_with_backend\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triton_key\n\u001b[0;32m--> 165\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mtriton_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtriton_key()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mhash()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Hash is upper case so that it can't contain any Python keywords.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/torch/utils/_triton.py:157\u001b[0m, in \u001b[0;36mtriton_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_backend\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m driver\n\u001b[0;32m--> 157\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_target\u001b[49m()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m make_backend(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/runtime/driver.py:30\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/runtime/driver.py:26\u001b[0m, in \u001b[0;36mLazyProxy._initialize_obj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/runtime/driver.py:12\u001b[0m, in \u001b[0;36m_create_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_drivers) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(active_drivers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactive_drivers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). There should only be one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactive_drivers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/backends/nvidia/driver.py:715\u001b[0m, in \u001b[0;36mCudaDriver.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutils \u001b[38;5;241m=\u001b[39m \u001b[43mCudaUtils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: make static\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlauncher_cls \u001b[38;5;241m=\u001b[39m CudaLauncher\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/backends/nvidia/driver.py:62\u001b[0m, in \u001b[0;36mCudaUtils.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_module_from_src\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver.c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda_utils\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_dirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibraries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibraries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_binary \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mload_binary\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_device_properties \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_device_properties\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/runtime/build.py:88\u001b[0m, in \u001b[0;36mcompile_module_from_src\u001b[0;34m(src, name, library_dirs, include_dirs, libraries)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     87\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(src)\n\u001b[0;32m---> 88\u001b[0m so \u001b[38;5;241m=\u001b[39m \u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary_dirs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_dirs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibraries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(so, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     90\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mput(f\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/triton/runtime/build.py:32\u001b[0m, in \u001b[0;36m_build\u001b[0;34m(name, src, srcdir, library_dirs, include_dirs, libraries)\u001b[0m\n\u001b[1;32m     30\u001b[0m     cc \u001b[38;5;241m=\u001b[39m gcc \u001b[38;5;28;01mif\u001b[39;00m gcc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m clang\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find C compiler. Please specify via CC environment variable or set triton.knobs.build.impl.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# This function was renamed and made public in Python 3.10\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sysconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_default_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mInductorError\u001b[0m: RuntimeError: Failed to find C compiler. Please specify via CC environment variable or set triton.knobs.build.impl.\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Run the Fine-Tuning Training ---\n",
    "# Finally, you can start the training process. This function works just like the\n",
    "# standard `train` method but includes the `pretrained_weights` argument.\n",
    "# nnU-Net will load the weights from the specified checkpoint file before starting\n",
    "# the training, effectively fine-tuning the model on your new data.\n",
    "# This wraps: nnUNetv2_train -pretrained_weights CLI\n",
    "print(f\"Step 4: Starting fine-tuning on Dataset {FINETUNE_DATASET_ID}...\")\n",
    "api.finetune(\n",
    "    finetune_dataset_id=FINETUNE_DATASET_ID,\n",
    "    configuration='3d_fullres',\n",
    "    fold=FOLD,\n",
    "    pretrained_checkpoint_path=PRETRAINED_CHECKPOINT_PATH,\n",
    "    plans_identifier=FINETUNE_PLANS_ID,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    initial_lr=INIT_LR\n",
    ")\n",
    "print(\"\\nFine-tuning process has been started!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c1c3-a1e5-409e-8a82-9ce3b984df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 5: Run the inference of the newly fine tunned model ---\n",
    "# This wraps:\n",
    "print(f\"Step 5: Infering fine-tuned model on a testing dataset\")\n",
    "api.predict(\n",
    "    input_folder=INPUT_FOLDER_INFER,\n",
    "    output_folder=OUTPUT_FOLDER_INFER_FINETUNE,\n",
    "    dataset_name_or_id=DST_DATA_NAME,\n",
    "    plans_identifier=FINETUNE_PLANS_ID,\n",
    "    configuration='3d_fullres',\n",
    "    folds=[FOLD]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9924f0c-9a96-413d-83fd-348ce145e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- Step 5+: Run the inference of the original pretrained model ---\n",
    "## This wraps:\n",
    "print(f\"Step 5: Infering pretrained model on a testing dataset\")\n",
    "api.predict(\n",
    "    input_folder=INPUT_FOLDER_INFER,\n",
    "    output_folder=OUTPUT_FOLDER_INFER_PRETRAINED,\n",
    "    dataset_name_or_id=\"Dataset770_BraTSGLIPreCropRegion\",\n",
    "    plans_identifier=\"nnUNetResEncUNetPlans\",\n",
    "    configuration='3d_fullres',\n",
    "    folds=[FOLD]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
