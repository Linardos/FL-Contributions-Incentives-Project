{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407e96c3-23ba-4959-a600-c3b0492751a9",
   "metadata": {},
   "source": [
    "https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc50d7e6-35e1-452d-9cf8-9647e2715952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-10-28 11:56:00.611755731 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.6.dev2542\n",
      "Numpy version: 2.1.2\n",
      "Pytorch version: 2.8.0+cu126\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 612f3dd3cba4d73cfcea4b5329079e20aa31523d\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/m_quant_py310/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: 5.4.4\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.25.2\n",
      "scipy version: 1.15.3\n",
      "Pillow version: 11.0.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.23.0+cu126\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 7.0.0\n",
      "pandas version: 2.3.2\n",
      "einops version: 0.8.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "import onnxruntime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6207d9e8-9830-4d0d-9198-e4a905daed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./seg_ckpts\n"
     ]
    }
   ],
   "source": [
    "directory = \"./seg_ckpts\"\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393e5c5-1a6b-441b-a424-891dbfce31be",
   "metadata": {},
   "source": [
    "# Transforms/Preprocessing taken as is from MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54eddc6-f30e-4b2d-b092-8fad6bc3096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n"
     ]
    }
   ],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge label 2 and label 3 to construct TC\n",
    "            result.append(torch.logical_or(d[key] == 2, d[key] == 3))\n",
    "            # merge labels 1, 2 and 3 to construct WT\n",
    "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 2)\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220cde2-ff64-4bad-abec-63db1231f19f",
   "metadata": {},
   "source": [
    "# Load the data in a federated manner ready for the Data Valuation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91cdedc-d346-4829-a551-c73b1042f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████| 511/511 [22:14<00:00,  2.61s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 6/6 [00:18<00:00,  3.05s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 15/15 [00:42<00:00,  2.84s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 47/47 [02:22<00:00,  3.04s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 22/22 [00:56<00:00,  2.58s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 34/34 [01:34<00:00,  2.78s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 12/12 [00:32<00:00,  2.71s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 8/8 [00:19<00:00,  2.43s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.72s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████| 8/8 [00:22<00:00,  2.76s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████| 47/47 [04:21<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train per-centre sizes: {1: 511, 2: 6, 3: 15, 4: 47, 5: 22, 6: 34, 7: 12, 8: 8, 9: 4, 10: 8}\n",
      "validation size: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MINE!!\n",
    "\n",
    "import os, copy, time, random, torch, numpy as np                                 \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "import glob, nibabel as nib, pandas as pd\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Orientationd, ScaleIntensityd,\n",
    "    RandFlipd, RandSpatialCropd, Compose, SelectItemsd\n",
    ")\n",
    "\n",
    "from utils import *\n",
    "  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------------------------------\n",
    "# 0. paths & meta-data (unchanged) ---------------------------\n",
    "# -----------------------------------------------------------\n",
    "BRATS_DIR = \"/mnt/d/Datasets/FETS_data/MICCAI_FeTS2022_TrainingData\"\n",
    "CSV_PATH  = f\"{BRATS_DIR}/partitioning_1.csv\"\n",
    "MODALITIES = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "LABEL_KEY  = \"seg\"\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. read partition file  ➜  { id : [subjects] } ------------\n",
    "# -----------------------------------------------------------\n",
    "part_df       = pd.read_csv(CSV_PATH)\n",
    "partition_map = (\n",
    "    part_df.groupby(\"Partition_ID\")[\"Subject_ID\"]\n",
    "           .apply(list).to_dict()\n",
    ")                               # keys are 1 … 23\n",
    "\n",
    "VAL_CENTRES = {21, 22, 23}          # ← our hold-out set\n",
    "# VAL_CENTRES = {22, 23}          # ← our sanity set\n",
    "\n",
    "# split once, reuse everywhere\n",
    "train_partitions = {cid: sids for cid, sids in partition_map.items()\n",
    "                    if cid not in VAL_CENTRES}\n",
    "val_subjects     = sum((partition_map[cid] for cid in VAL_CENTRES), [])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. helper to build MONAI-style record dicts ----------------\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def build_records(subject_ids):\n",
    "    recs = []\n",
    "    for sid in subject_ids:\n",
    "        sdir = f\"{BRATS_DIR}/{sid}\"\n",
    "        images = [f\"{sdir}/{sid}_{m}.nii.gz\" for m in MODALITIES]  # 4 modalities\n",
    "        recs.append({\"image\": images, \"label\": f\"{sdir}/{sid}_{LABEL_KEY}.nii.gz\"})\n",
    "    return recs\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. MONAI CacheDatasets ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "# ── client-wise training sets ───────────────────────────────\n",
    "CUT_OFF, FRAC, SEED = 10, 1.0, 42\n",
    "rng = random.Random(SEED)\n",
    "\n",
    "train_datasets = {}\n",
    "for cid, subj_ids in train_partitions.items():\n",
    "    if cid > CUT_OFF:                                    # keep your cap\n",
    "        break\n",
    "    k = max(1, int(len(subj_ids) * FRAC))                # e.g. 30 %\n",
    "    sample_ids = rng.sample(subj_ids, k)\n",
    "    train_datasets[cid] = CacheDataset(\n",
    "        build_records(sample_ids), transform=train_transform, cache_rate=1\n",
    "    )\n",
    "\n",
    "# ── single validation dataset made from *all* val subjects ─\n",
    "val_dataset = CacheDataset(\n",
    "    build_records(val_subjects), transform=val_transform, cache_rate=1\n",
    ")\n",
    "\n",
    "print(\"train per-centre sizes:\", {k: len(v) for k, v in train_datasets.items()})\n",
    "print(\"validation size:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e71cf-50c6-4bf1-96a7-97f8ef6f79f1",
   "metadata": {},
   "source": [
    "# Create Model, Loss, Optimizer (as is from MONAI tutorial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0da8ff-38db-4a47-a77b-0558301d37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 300\n",
    "val_interval = 1\n",
    "VAL_AMP = True\n",
    "\n",
    "# standard PyTorch program style: create SegResNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "global_model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)\n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(240, 240, 160),\n",
    "            sw_batch_size=1,\n",
    "            predictor=global_model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "# use amp to accelerate training\n",
    "scaler = torch.GradScaler(\"cuda\")\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae7765-94e1-4f8f-8bc2-c5463d5cc041",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237ce6c9-54d4-4b1b-9234-27cb18e1f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                                | 0/47 [00:00<?, ?it/s]Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 47/47 [00:15<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice before any training: (0.03423714637756348, 0.02744104526937008, 0.01803244650363922, 0.05723793804645538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataset, device, batch_size=1):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    dice_metric.reset()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)          # already multi-channel (WT/TC/ET) floats\n",
    "\n",
    "            # sliding-window inference (your helper)\n",
    "            logits = inference(inputs)                  # [B, 3, D, H, W]\n",
    "\n",
    "            # tensor-wise post-processing (no decollate, no meta juggling)\n",
    "            preds = torch.sigmoid(logits)\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            # accumulate Dice on tensors directly\n",
    "            dice_metric(y_pred=preds, y=labels)\n",
    "            dice_metric_batch(y_pred=preds, y=labels)\n",
    "\n",
    "    mean_dice = dice_metric.aggregate().item()\n",
    "    metric_batch = dice_metric_batch.aggregate()\n",
    "    metric_tc = metric_batch[0].item()\n",
    "    metric_wt = metric_batch[1].item()\n",
    "    metric_et = metric_batch[2].item()\n",
    "    dice_metric.reset()\n",
    "    dice_metric_batch.reset()\n",
    "    \n",
    "    return mean_dice, metric_tc, metric_wt, metric_et\n",
    "    \n",
    "print(\"Dice before any training:\", evaluate_model(global_model, val_dataset, device)) # quick sanity check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bdb623-69ae-42ff-bf8a-cb885b284ab6",
   "metadata": {},
   "source": [
    "# Train federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba799f-6113-4b46-b9d6-f85d5b40e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cf06d6e2044a2a84d57f2e82407072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice before any training: (0.03423714637756348, 0.02744104526937008, 0.01803244650363922, 0.05723793804645538)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e32795b0bf341999e7c11a62907125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global rounds:   0%|                                                                             | 0/50 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523218eae36249ea91977ddc0d826d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " clients:   0%|                                                                                  | 0/10 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange   # trange == tqdm(range())\n",
    "from collections import OrderedDict\n",
    "\n",
    "def average_weights(state_dicts, fractions):\n",
    "    \"\"\"\n",
    "    Federated averaging with client fractions (must sum to 1).\n",
    "    state_dicts: list of state_dicts (same keys)\n",
    "    fractions:   list of floats, same length, sum≈1\n",
    "    \"\"\"\n",
    "    avg_sd = OrderedDict()\n",
    "    for k in state_dicts[0].keys():\n",
    "        avg = 0.0\n",
    "        for sd, w in zip(state_dicts, fractions):\n",
    "            avg += sd[k] * w\n",
    "        avg_sd[k] = avg\n",
    "    return avg_sd\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# 1. one-client update (returns weights + mean loss)          │\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def local_train(model, loader, device, lr=1e-4, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a local copy of the global model on one client's DataLoader.\n",
    "    Uses your DiceLoss (multi-label, sigmoid) and full crops from transforms.\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    model.train()\n",
    "\n",
    "    # reuse your loss choice; or inline DiceLoss the same way\n",
    "    crit = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True,\n",
    "                    to_onehot_y=False, sigmoid=True).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        running = 0.0\n",
    "        for batch in loader:\n",
    "            img = batch[\"image\"].to(device)   # [B, 4, D, H, W]\n",
    "            msk = batch[\"label\"].to(device)   # [B, 3, D, H, W]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(img)               # [B, 3, D, H, W]\n",
    "            loss = crit(logits, msk)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "        epoch_losses.append(running / max(1, len(loader)))\n",
    "\n",
    "    return model.state_dict(), float(np.mean(epoch_losses))\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# 2. FedAvg training loop (simple tqdm + clean prints)        │\n",
    "# ────────────────────────────────────────────────────────────\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "ROUNDS, LOCAL_EPOCHS, LR, BATCH = 50, 1, 1e-4, 1\n",
    "\n",
    "idxs_users = list(train_datasets.keys())\n",
    "sizes      = {k: len(ds) for k, ds in train_datasets.items()}\n",
    "total_n    = sum(sizes.values())\n",
    "fractions  = [sizes[k] / total_n for k in idxs_users]\n",
    "\n",
    "print(\"Dice before any training:\", evaluate_model(global_model, val_dataset, device))\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_round = -1\n",
    "best_metrics_rounds_and_time = [[], [], []]\n",
    "round_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_tc = []\n",
    "metric_values_wt = []\n",
    "metric_values_et = []\n",
    "\n",
    "total_start = time.time()\n",
    "for rnd in trange(1, ROUNDS + 1, desc=\"Global rounds\", position=0, leave=True, dynamic_ncols=True):\n",
    "    local_weights, client_losses = [], []\n",
    "\n",
    "    # client bar (line 1)\n",
    "    for cid in tqdm(idxs_users, desc=\" clients\", position=1, leave=False, total=len(idxs_users), dynamic_ncols=True):\n",
    "        loader = DataLoader(train_datasets[cid], batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        w, loss = local_train(global_model, loader, device, lr=LR, epochs=LOCAL_EPOCHS)\n",
    "        local_weights.append(w); client_losses.append(loss)\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights, fractions))\n",
    "\n",
    "    # eval bar (line 2)\n",
    "    mean_dice, metric_tc, metric_wt, metric_et = evaluate_model(global_model, test_dataset, device)\n",
    "    \n",
    "    metric_values.append(mean_dice)\n",
    "    metric_values_tc.append(metric_tc)\n",
    "    metric_values_wt.append(metric_wt)\n",
    "    metric_values_et.append(metric_et)\n",
    "    \n",
    "    mean_loss = float(np.mean(client_losses))\n",
    "    round_loss_values.append(mean_loss)\n",
    "\n",
    "\n",
    "    if mean_dice > best_metric:\n",
    "        best_metric = mean_dice\n",
    "        best_metric_round = rnd + 1\n",
    "        best_metrics_rounds_and_time[0].append(best_metric)\n",
    "        best_metrics_rounds_and_time[1].append(best_metric_epoch)\n",
    "        best_metrics_rounds_and_time[2].append(time.time() - total_start)\n",
    "        torch.save(\n",
    "            global_model.state_dict(),\n",
    "            os.path.join(root_dir, \"best_metric_model.pth\"),\n",
    "        )\n",
    "        print(\"saved new best metric model\")\n",
    "    \n",
    "    tqdm.write(f\"Round {rnd:02d}:  mean-loss = {mean_loss:.4f}   mean-Dice = {mean_dice:.4f}    TC-Dice = {metric_tc:.4f}    TC-Dice = {metric_wt:.4f}    TC-Dice = {metric_tc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd58c6-cc61-4b62-a8ff-5d85261a2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Federated Round Aggregate Loss\")\n",
    "x = [i + 1 for i in range(len(round_loss_values))]\n",
    "y = round_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(\"train\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Val Mean Dice TC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
    "y = metric_values_tc\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Val Mean Dice WT\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
    "y = metric_values_wt\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"brown\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Val Mean Dice ET\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
    "y = metric_values_et\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"purple\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
